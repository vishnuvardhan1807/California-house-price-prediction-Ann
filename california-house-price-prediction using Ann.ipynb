{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "personal-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sealed-aerospace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training before splitting to valid is (15480, 8)\n",
      "The size of testing before splitting to valid is (15480,)\n",
      "The size of training after splitting to valid is (11610, 8)\n",
      "The size of testing after splitting to valid is (11610,)\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing() #loading the data\n",
    "X_train_full , X_test , y_train_full , y_test = train_test_split(housing.data , housing.target) #training and testing set\n",
    "X_train , X_valid , y_train , y_valid = train_test_split(X_train_full,y_train_full) #training and validation set\n",
    "\n",
    "print(f\"The size of training before splitting to valid is {X_train_full.shape}\")\n",
    "print(f\"The size of testing before splitting to valid is {y_train_full.shape}\")\n",
    "\n",
    "print(f\"The size of training after splitting to valid is {X_train.shape}\")\n",
    "print(f\"The size of testing after splitting to valid is {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silver-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-ethics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollow-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.9056 - mean_squared_error: 1.9056 - val_loss: 0.5532 - val_mean_squared_error: 0.5532\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.5166 - mean_squared_error: 0.5166 - val_loss: 4.1788 - val_mean_squared_error: 4.1788\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 714us/step - loss: 1.3842 - mean_squared_error: 1.3842 - val_loss: 0.4534 - val_mean_squared_error: 0.4534\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.4774 - mean_squared_error: 0.4774 - val_loss: 0.3870 - val_mean_squared_error: 0.3870\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.4140 - mean_squared_error: 0.4140 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.3995 - mean_squared_error: 0.3995 - val_loss: 0.3673 - val_mean_squared_error: 0.3673\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.3643 - val_mean_squared_error: 0.3643\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.3864 - mean_squared_error: 0.3864 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.3766 - mean_squared_error: 0.3766 - val_loss: 0.3655 - val_mean_squared_error: 0.3655\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 690us/step - loss: 0.3768 - mean_squared_error: 0.3768 - val_loss: 0.3558 - val_mean_squared_error: 0.3558\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.3562 - val_mean_squared_error: 0.3562\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 684us/step - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.3545 - val_mean_squared_error: 0.3545\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 742us/step - loss: 0.3776 - mean_squared_error: 0.3776 - val_loss: 0.3525 - val_mean_squared_error: 0.3525\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 759us/step - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.3508 - val_mean_squared_error: 0.3508\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.3517 - mean_squared_error: 0.3517 - val_loss: 0.3481 - val_mean_squared_error: 0.3481\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 684us/step - loss: 0.3716 - mean_squared_error: 0.3716 - val_loss: 0.3462 - val_mean_squared_error: 0.3462\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 707us/step - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.3436 - val_mean_squared_error: 0.3436\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.3445 - mean_squared_error: 0.3445 - val_loss: 0.3597 - val_mean_squared_error: 0.3597\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.3428 - val_mean_squared_error: 0.3428\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.3574 - mean_squared_error: 0.3574 - val_loss: 0.3397 - val_mean_squared_error: 0.3397\n"
     ]
    }
   ],
   "source": [
    "model  = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation=\"relu\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"sgd\",   metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "history = model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nervous-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up tensorboard\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir,\"mylogs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H-%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prompt-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3621 - mean_squared_error: 0.3621 - val_loss: 0.3412 - val_mean_squared_error: 0.3412\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3605 - mean_squared_error: 0.3605 - val_loss: 0.3379 - val_mean_squared_error: 0.3379\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.3624 - mean_squared_error: 0.3624 - val_loss: 0.3394 - val_mean_squared_error: 0.3394\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.3569 - mean_squared_error: 0.3569 - val_loss: 0.3350 - val_mean_squared_error: 0.3350\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3542 - mean_squared_error: 0.3542 - val_loss: 0.3338 - val_mean_squared_error: 0.3338\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.3555 - mean_squared_error: 0.3555 - val_loss: 0.3337 - val_mean_squared_error: 0.3337\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.3545 - mean_squared_error: 0.3545 - val_loss: 0.3317 - val_mean_squared_error: 0.3317\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.3507 - mean_squared_error: 0.3507 - val_loss: 0.3317 - val_mean_squared_error: 0.3317\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.3493 - mean_squared_error: 0.3493 - val_loss: 0.3301 - val_mean_squared_error: 0.3301\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.3498 - mean_squared_error: 0.3498 - val_loss: 0.3851 - val_mean_squared_error: 0.3851\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.3615 - mean_squared_error: 0.3615 - val_loss: 0.3318 - val_mean_squared_error: 0.3318\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.3503 - mean_squared_error: 0.3503 - val_loss: 0.3292 - val_mean_squared_error: 0.3292\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.3455 - mean_squared_error: 0.3455 - val_loss: 0.3300 - val_mean_squared_error: 0.3300\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3453 - mean_squared_error: 0.3453 - val_loss: 0.3263 - val_mean_squared_error: 0.3263\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3477 - mean_squared_error: 0.3477 - val_loss: 0.3251 - val_mean_squared_error: 0.3251\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 720us/step - loss: 0.3465 - mean_squared_error: 0.3465 - val_loss: 0.3297 - val_mean_squared_error: 0.3297\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.3418 - mean_squared_error: 0.3418 - val_loss: 0.3225 - val_mean_squared_error: 0.3225\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.3689 - mean_squared_error: 0.3689 - val_loss: 0.3304 - val_mean_squared_error: 0.3304\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.3545 - mean_squared_error: 0.3545 - val_loss: 0.3315 - val_mean_squared_error: 0.3315\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 720us/step - loss: 0.3441 - mean_squared_error: 0.3441 - val_loss: 0.3275 - val_mean_squared_error: 0.3275\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid),callbacks=[tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italian-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "final-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 487us/step - loss: 0.3313 - mean_squared_error: 0.3313\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fifteen-webmaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1369715],\n",
       "       [2.5846744],\n",
       "       [2.2402983]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = X_test[:3]\n",
    "y_pred = model.predict(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "competitive-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.64 , 1.998, 1.75 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "direct-switch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "provincial-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2912 - mean_squared_error: 2.2912 - val_loss: 0.5521 - val_mean_squared_error: 0.5521\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4937 - mean_squared_error: 0.4937 - val_loss: 0.4068 - val_mean_squared_error: 0.4068\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.4013 - mean_squared_error: 0.4013 - val_loss: 0.3780 - val_mean_squared_error: 0.3780\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3907 - mean_squared_error: 0.3907 - val_loss: 0.3699 - val_mean_squared_error: 0.3699\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.3500 - val_mean_squared_error: 0.3500\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3699 - mean_squared_error: 0.3699 - val_loss: 0.3604 - val_mean_squared_error: 0.3604\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3545 - mean_squared_error: 0.3545 - val_loss: 0.3397 - val_mean_squared_error: 0.3397\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3622 - mean_squared_error: 0.3622 - val_loss: 0.3309 - val_mean_squared_error: 0.3309\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.3435 - mean_squared_error: 0.3435 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3431 - mean_squared_error: 0.3431 - val_loss: 0.3232 - val_mean_squared_error: 0.3232\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.3451 - mean_squared_error: 0.3451 - val_loss: 0.3278 - val_mean_squared_error: 0.3278\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.3471 - mean_squared_error: 0.3471 - val_loss: 0.3907 - val_mean_squared_error: 0.3907\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3445 - mean_squared_error: 0.3445 - val_loss: 0.3960 - val_mean_squared_error: 0.3960\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.3297 - mean_squared_error: 0.3297 - val_loss: 0.3606 - val_mean_squared_error: 0.3606\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3317 - mean_squared_error: 0.3317 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3170 - mean_squared_error: 0.3170 - val_loss: 0.2991 - val_mean_squared_error: 0.2991\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3177 - mean_squared_error: 0.3177 - val_loss: 0.3241 - val_mean_squared_error: 0.3241\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3108 - mean_squared_error: 0.3108 - val_loss: 0.3064 - val_mean_squared_error: 0.3064\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3071 - mean_squared_error: 0.3071 - val_loss: 0.3181 - val_mean_squared_error: 0.3181\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3104 - mean_squared_error: 0.3104 - val_loss: 0.3031 - val_mean_squared_error: 0.3031\n"
     ]
    }
   ],
   "source": [
    "#using keras functional api to build complex models\n",
    "\n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_,hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_],outputs=[output])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\",   metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "history = model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unnecessary-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 577us/step - loss: 0.3127 - mean_squared_error: 0.3127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3126838505268097, 0.3126838505268097]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exceptional-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.1902 - mean_squared_error: 2.1902 - val_loss: 0.6222 - val_mean_squared_error: 0.6222\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.5707 - mean_squared_error: 0.5707 - val_loss: 0.4763 - val_mean_squared_error: 0.4763\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.4683 - mean_squared_error: 0.4683 - val_loss: 0.4390 - val_mean_squared_error: 0.4390\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.4493 - mean_squared_error: 0.4493 - val_loss: 0.4049 - val_mean_squared_error: 0.4049\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.3984 - mean_squared_error: 0.3984 - val_loss: 0.3690 - val_mean_squared_error: 0.3690\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.3861 - mean_squared_error: 0.3861 - val_loss: 0.3557 - val_mean_squared_error: 0.3557\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.3673 - mean_squared_error: 0.3673 - val_loss: 0.3657 - val_mean_squared_error: 0.3657\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.3642 - mean_squared_error: 0.3642 - val_loss: 0.3405 - val_mean_squared_error: 0.3405\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3503 - mean_squared_error: 0.3503 - val_loss: 0.3360 - val_mean_squared_error: 0.3360\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3509 - mean_squared_error: 0.3509 - val_loss: 0.3306 - val_mean_squared_error: 0.3306\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.3407 - val_mean_squared_error: 0.3407\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3523 - mean_squared_error: 0.3523 - val_loss: 0.3311 - val_mean_squared_error: 0.3311\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.4233 - val_mean_squared_error: 0.4233\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3532 - mean_squared_error: 0.3532 - val_loss: 0.3901 - val_mean_squared_error: 0.3901\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.3446 - mean_squared_error: 0.3446 - val_loss: 0.3137 - val_mean_squared_error: 0.3137\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.3335 - val_mean_squared_error: 0.3335\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3347 - mean_squared_error: 0.3347 - val_loss: 0.3325 - val_mean_squared_error: 0.3325\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3234 - mean_squared_error: 0.3234 - val_loss: 0.3104 - val_mean_squared_error: 0.3104\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3297 - mean_squared_error: 0.3297 - val_loss: 0.3162 - val_mean_squared_error: 0.3162\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3327 - mean_squared_error: 0.3327 - val_loss: 0.3496 - val_mean_squared_error: 0.3496\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.3241 - val_mean_squared_error: 0.3241\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3338 - mean_squared_error: 0.3338 - val_loss: 0.3043 - val_mean_squared_error: 0.3043\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3430 - mean_squared_error: 0.3430 - val_loss: 0.3022 - val_mean_squared_error: 0.3022\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.3219 - mean_squared_error: 0.3219 - val_loss: 0.3083 - val_mean_squared_error: 0.3083\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.3121 - val_mean_squared_error: 0.3121\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.3356 - val_mean_squared_error: 0.3356\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.3184 - mean_squared_error: 0.3184 - val_loss: 0.3247 - val_mean_squared_error: 0.3247\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3150 - mean_squared_error: 0.3150 - val_loss: 0.3396 - val_mean_squared_error: 0.3396\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.3004 - val_mean_squared_error: 0.3004\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.3155 - val_mean_squared_error: 0.3155\n"
     ]
    }
   ],
   "source": [
    "# sending subsets of features refer hands on machine learning page 310\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5],name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6],name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A,hidden2])\n",
    "output = keras.layers.Dense(1,name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A,input_B],outputs=[output])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\",   metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "X_train_A,X_train_B = X_train[:,:5],X_train[:,2:]\n",
    "X_valid_A,X_valid_B = X_valid[:,:5],X_valid[:,2:]\n",
    "X_test_A,X_test_B = X_test[:,:5],X_test[:,2:]\n",
    "X_new_A,X_new_B = X_test_A[:3],X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A,X_train_B),y_train,epochs=30,validation_data=((X_valid_A,X_valid_B),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chief-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 491us/step - loss: 0.3855 - mean_squared_error: 0.3855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38554373383522034, 0.38554373383522034]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A,X_test_B),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acknowledged-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.254132 ],\n",
       "       [2.3823137],\n",
       "       [2.0839293]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict((X_new_A,X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opponent-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.64 , 1.998, 1.75 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "widespread-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0197 - output_loss: 1.9192 - aux_output_loss: 2.9246 - val_loss: 0.6387 - val_output_loss: 0.6033 - val_aux_output_loss: 0.9576\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5047 - output_loss: 0.4684 - aux_output_loss: 0.8316 - val_loss: 0.4513 - val_output_loss: 0.4227 - val_aux_output_loss: 0.7090\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4331 - output_loss: 0.4113 - aux_output_loss: 0.6295 - val_loss: 0.4256 - val_output_loss: 0.4043 - val_aux_output_loss: 0.6170\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4335 - output_loss: 0.4109 - aux_output_loss: 0.6370 - val_loss: 0.4205 - val_output_loss: 0.4057 - val_aux_output_loss: 0.5543\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4163 - output_loss: 0.4001 - aux_output_loss: 0.5621 - val_loss: 0.3816 - val_output_loss: 0.3677 - val_aux_output_loss: 0.5071\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.3866 - output_loss: 0.3746 - aux_output_loss: 0.4952 - val_loss: 0.3747 - val_output_loss: 0.3632 - val_aux_output_loss: 0.4781\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3958 - output_loss: 0.3845 - aux_output_loss: 0.4972 - val_loss: 0.3588 - val_output_loss: 0.3485 - val_aux_output_loss: 0.4517\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3830 - output_loss: 0.3739 - aux_output_loss: 0.4643 - val_loss: 0.3581 - val_output_loss: 0.3483 - val_aux_output_loss: 0.4461\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3687 - output_loss: 0.3600 - aux_output_loss: 0.4477 - val_loss: 0.3852 - val_output_loss: 0.3786 - val_aux_output_loss: 0.4450\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - output_loss: 0.3837 - aux_output_loss: 0.4442 - val_loss: 0.3423 - val_output_loss: 0.3333 - val_aux_output_loss: 0.4239\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3544 - output_loss: 0.3467 - aux_output_loss: 0.4237 - val_loss: 0.3319 - val_output_loss: 0.3234 - val_aux_output_loss: 0.4078\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3572 - output_loss: 0.3501 - aux_output_loss: 0.4212 - val_loss: 0.3304 - val_output_loss: 0.3227 - val_aux_output_loss: 0.3997\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3443 - output_loss: 0.3375 - aux_output_loss: 0.4061 - val_loss: 0.3511 - val_output_loss: 0.3455 - val_aux_output_loss: 0.4011\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3441 - output_loss: 0.3375 - aux_output_loss: 0.4031 - val_loss: 0.3258 - val_output_loss: 0.3173 - val_aux_output_loss: 0.4025\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3491 - output_loss: 0.3405 - aux_output_loss: 0.4266 - val_loss: 0.3240 - val_output_loss: 0.3164 - val_aux_output_loss: 0.3925\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - output_loss: 0.3363 - aux_output_loss: 0.4010 - val_loss: 0.3217 - val_output_loss: 0.3141 - val_aux_output_loss: 0.3903\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3349 - output_loss: 0.3280 - aux_output_loss: 0.3969 - val_loss: 0.3844 - val_output_loss: 0.3821 - val_aux_output_loss: 0.4054\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3660 - output_loss: 0.3613 - aux_output_loss: 0.4076 - val_loss: 0.3199 - val_output_loss: 0.3128 - val_aux_output_loss: 0.3839\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3346 - output_loss: 0.3281 - aux_output_loss: 0.3938 - val_loss: 0.3168 - val_output_loss: 0.3100 - val_aux_output_loss: 0.3785\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3431 - output_loss: 0.3374 - aux_output_loss: 0.3946 - val_loss: 0.3160 - val_output_loss: 0.3089 - val_aux_output_loss: 0.3797\n"
     ]
    }
   ],
   "source": [
    "#using an auxilary output for regulariztion page 312 in hands on machine learning\n",
    "\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5],name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6],name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A,hidden2])\n",
    "output = keras.layers.Dense(1,name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1,name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs = [input_A,input_B],outputs=[output,aux_output])\n",
    "\n",
    "model.compile(loss=[\"mse\",\"mse\"],loss_weights=[0.9,0.1],optimizer=\"adam\")\n",
    "\n",
    "X_train_A,X_train_B = X_train[:,:5],X_train[:,2:]\n",
    "X_valid_A,X_valid_B = X_valid[:,:5],X_valid[:,2:]\n",
    "X_test_A,X_test_B = X_test[:,:5],X_test[:,2:]\n",
    "X_new_A,X_new_B = X_test_A[:3],X_test_B[:3]\n",
    "\n",
    "history = model.fit([X_train_A,X_train_B],[y_train,y_train],epochs=20,validation_data=([X_valid_A,X_valid_B],[y_valid,y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unable-board",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 691us/step - loss: 0.3489 - output_loss: 0.3425 - aux_output_loss: 0.4060\n"
     ]
    }
   ],
   "source": [
    "total_loss,main_loss,aux_loss = model.evaluate([X_test_A,X_test_B],[y_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corrected-estonia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.2759999],\n",
       "        [2.3461738],\n",
       "        [1.9932345]], dtype=float32),\n",
       " array([[1.2373835],\n",
       "        [2.200038 ],\n",
       "        [2.000543 ]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X_new_A,X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advance-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model refer hands on machine learning page 314\n",
    "model.save(\"californiamodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "extensive-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model refer hands on machine learning page 315\n",
    "models = keras.models.load_model(\"californiamodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supreme-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3657 - output_loss: 0.3608 - aux_output_loss: 0.4091 - val_loss: 0.3114 - val_output_loss: 0.3036 - val_aux_output_loss: 0.3822\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3323 - output_loss: 0.3253 - aux_output_loss: 0.3950 - val_loss: 0.3136 - val_output_loss: 0.3062 - val_aux_output_loss: 0.3800\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3271 - output_loss: 0.3205 - aux_output_loss: 0.3865 - val_loss: 0.3121 - val_output_loss: 0.3045 - val_aux_output_loss: 0.3801\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3248 - output_loss: 0.3185 - aux_output_loss: 0.3817 - val_loss: 0.3143 - val_output_loss: 0.3073 - val_aux_output_loss: 0.3774\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3258 - output_loss: 0.3196 - aux_output_loss: 0.3814 - val_loss: 0.3090 - val_output_loss: 0.3023 - val_aux_output_loss: 0.3691\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3286 - output_loss: 0.3230 - aux_output_loss: 0.3791 - val_loss: 0.3131 - val_output_loss: 0.3063 - val_aux_output_loss: 0.3735\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3426 - output_loss: 0.3366 - aux_output_loss: 0.3967 - val_loss: 0.3621 - val_output_loss: 0.3595 - val_aux_output_loss: 0.3854\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3369 - output_loss: 0.3320 - aux_output_loss: 0.3813 - val_loss: 0.3083 - val_output_loss: 0.3017 - val_aux_output_loss: 0.3683\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3211 - output_loss: 0.3150 - aux_output_loss: 0.3753 - val_loss: 0.3234 - val_output_loss: 0.3176 - val_aux_output_loss: 0.3759\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3224 - output_loss: 0.3168 - aux_output_loss: 0.3729 - val_loss: 0.3110 - val_output_loss: 0.3044 - val_aux_output_loss: 0.3704\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3246 - output_loss: 0.3190 - aux_output_loss: 0.3747 - val_loss: 0.3180 - val_output_loss: 0.3117 - val_aux_output_loss: 0.3740\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.3212 - output_loss: 0.3156 - aux_output_loss: 0.3718 - val_loss: 0.3304 - val_output_loss: 0.3244 - val_aux_output_loss: 0.3845\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3210 - output_loss: 0.3155 - aux_output_loss: 0.3706 - val_loss: 0.3182 - val_output_loss: 0.3123 - val_aux_output_loss: 0.3712\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3165 - output_loss: 0.3111 - aux_output_loss: 0.3655 - val_loss: 0.3156 - val_output_loss: 0.3087 - val_aux_output_loss: 0.3774\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3163 - output_loss: 0.3108 - aux_output_loss: 0.3657 - val_loss: 0.3064 - val_output_loss: 0.3003 - val_aux_output_loss: 0.3615\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3175 - output_loss: 0.3121 - aux_output_loss: 0.3660 - val_loss: 0.3151 - val_output_loss: 0.3096 - val_aux_output_loss: 0.3643\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3169 - output_loss: 0.3115 - aux_output_loss: 0.3656 - val_loss: 0.3219 - val_output_loss: 0.3157 - val_aux_output_loss: 0.3780\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3143 - output_loss: 0.3089 - aux_output_loss: 0.3636 - val_loss: 0.3123 - val_output_loss: 0.3060 - val_aux_output_loss: 0.3682\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3244 - output_loss: 0.3191 - aux_output_loss: 0.3718 - val_loss: 0.3124 - val_output_loss: 0.3059 - val_aux_output_loss: 0.3706\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3186 - output_loss: 0.3135 - aux_output_loss: 0.3645 - val_loss: 0.3053 - val_output_loss: 0.2989 - val_aux_output_loss: 0.3627\n"
     ]
    }
   ],
   "source": [
    "history1 = models.fit([X_train_A,X_train_B],[y_train,y_train],epochs=20,validation_data=([X_valid_A,X_valid_B],[y_valid,y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sporting-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 553us/step - loss: 0.3489 - output_loss: 0.3425 - aux_output_loss: 0.4060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34887218475341797, 0.3425232470035553, 0.40601256489753723]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test_A,X_test_B],[y_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "appropriate-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 917us/step - loss: 1.6675 - val_loss: 0.8251\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7113 - val_loss: 0.6636\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 666us/step - loss: 0.6256 - val_loss: 0.5382\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 667us/step - loss: 0.5306 - val_loss: 0.5046\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.5031 - val_loss: 0.4717\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.4825 - val_loss: 0.4513\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.4572 - val_loss: 0.4333\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.4416 - val_loss: 0.4344\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.4454 - val_loss: 0.4156\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.4309 - val_loss: 0.4118\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4217 - val_loss: 0.4081\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.4259 - val_loss: 0.3999\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.4174 - val_loss: 0.4006\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.3949 - val_loss: 0.3902\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.3937 - val_loss: 0.3940\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4135 - val_loss: 0.3860\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 759us/step - loss: 0.4075 - val_loss: 0.3849\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 720us/step - loss: 0.4238 - val_loss: 0.3826\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.3995 - val_loss: 0.3816\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.3848 - val_loss: 0.3764\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.3864 - val_loss: 0.3773\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 648us/step - loss: 0.3892 - val_loss: 0.3746\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 645us/step - loss: 0.4002 - val_loss: 0.3744\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.3982 - val_loss: 0.3733\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.3987 - val_loss: 0.3746\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.3915 - val_loss: 0.3723\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 654us/step - loss: 0.3792 - val_loss: 0.3673\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 663us/step - loss: 0.3903 - val_loss: 0.3694\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3715 - val_loss: 0.3704\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 654us/step - loss: 0.3806 - val_loss: 0.3697\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.3761 - val_loss: 0.3647\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.3701 - val_loss: 0.3653\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.3772 - val_loss: 0.3653\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.3748 - val_loss: 0.3622\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.3607 - val_loss: 0.3599\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.3658 - val_loss: 0.3601\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.3619 - val_loss: 0.3579\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.3725 - val_loss: 0.3581\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3758 - val_loss: 0.3575\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.3513 - val_loss: 0.3526\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.3691 - val_loss: 0.3559\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.3821 - val_loss: 0.3573\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.3703 - val_loss: 0.3542\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.3731 - val_loss: 0.3515\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3703 - val_loss: 0.3568\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.3702 - val_loss: 0.3556\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.3666 - val_loss: 0.3510\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.3718 - val_loss: 0.3578\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.3639 - val_loss: 0.3460\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.3648 - val_loss: 0.3568\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.3630 - val_loss: 0.3463\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3658 - val_loss: 0.3487\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.3686 - val_loss: 0.3514\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.3753 - val_loss: 0.3523\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.3646 - val_loss: 0.3452\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.3531 - val_loss: 0.3465\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.3629 - val_loss: 0.3473\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3650 - val_loss: 0.3465\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3555 - val_loss: 0.3482\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 663us/step - loss: 0.3715 - val_loss: 0.3431\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.3534 - val_loss: 0.3465\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 716us/step - loss: 0.3541 - val_loss: 0.3436\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.3659 - val_loss: 0.3544\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 679us/step - loss: 0.3521 - val_loss: 0.3402\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 720us/step - loss: 0.3526 - val_loss: 0.3554\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.3514 - val_loss: 0.3381\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.3573 - val_loss: 0.3466\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 716us/step - loss: 0.3559 - val_loss: 0.3356\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.3596 - val_loss: 0.3511\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 679us/step - loss: 0.3491 - val_loss: 0.3427\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 645us/step - loss: 0.3497 - val_loss: 0.3437\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.3599 - val_loss: 0.3389\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.3415 - val_loss: 0.3382\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.3406 - val_loss: 0.3390\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.3504 - val_loss: 0.3383\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.3550 - val_loss: 0.3466\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.3510 - val_loss: 0.3385\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.3389 - val_loss: 0.3445\n",
      "162/162 [==============================] - 0s 415us/step - loss: 0.3479\n"
     ]
    }
   ],
   "source": [
    "# fine tuning the parametres page 320 in hands on machine learning\n",
    "\n",
    "def build_model(n_hidden=1,n_nuerons=30,learning_rate=3e-3,inputshape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=inputshape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_nuerons,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimezer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\",optimizer=optimezer)\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid),callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdbe8252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.34794503450393677\n"
     ]
    }
   ],
   "source": [
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93b5c60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0393996, 2.5981898, 2.0838974], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "751ed1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.64 , 1.998, 1.75 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d804a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2497 - val_loss: 0.7263\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.6315 - val_loss: 0.6810\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5879 - val_loss: 0.6039\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.5775 - val_loss: 0.5564\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.5498 - val_loss: 0.5217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5720 - val_loss: 0.5914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.5459 - val_loss: 0.7602\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5680 - val_loss: 0.6175\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.6064 - val_loss: 0.6490\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.5585 - val_loss: 0.5303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.6179 - val_loss: 0.5969\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.6145 - val_loss: 0.5300\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5625 - val_loss: 0.5233\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.5651 - val_loss: 0.5316\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.5682 - val_loss: 0.6047\n",
      "121/121 [==============================] - 0s 388us/step - loss: 0.6149\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0298 - val_loss: 1.7393\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 7.0722 - val_loss: 20.4337\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 116.9452 - val_loss: 295.0478\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 1220.7406 - val_loss: 3989.8623\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 821.0515 - val_loss: 54808.6055\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 479678.3088 - val_loss: 755354.8750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 75345.7761 - val_loss: 10521311.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 10976285.9277 - val_loss: 142602880.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 8956086.1698 - val_loss: 1921869696.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 3287286592.6420 - val_loss: 25711304704.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 20303705064.4280 - val_loss: 351720374272.0000\n",
      "121/121 [==============================] - 0s 373us/step - loss: 15273191424.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7266 - val_loss: 37.4494\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 4.7305 - val_loss: 787.4811\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 23.2861 - val_loss: 20002.0156\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 3146.9017 - val_loss: 484387.0625\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 777792.3630 - val_loss: 11824039.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 380222.8745 - val_loss: 290100160.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 71953993.8858 - val_loss: 7051884032.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 1097243471.5391 - val_loss: 171920916480.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 23495547527.9012 - val_loss: 4181749137408.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 835670059243.9835 - val_loss: 101763730374656.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 1541254000623.1440 - val_loss: 2499297572552704.0000\n",
      "121/121 [==============================] - 0s 361us/step - loss: 387797865201664.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4843 - val_loss: 1.2284\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 1.0313 - val_loss: 0.9005\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.8144 - val_loss: 0.8087\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.7605 - val_loss: 0.7514\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.7297 - val_loss: 0.7122\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.7181 - val_loss: 0.6824\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.6974 - val_loss: 0.6599\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.6437 - val_loss: 0.6420\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.6734 - val_loss: 0.6261\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.6485 - val_loss: 0.6123\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.6334 - val_loss: 0.6011\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.6346 - val_loss: 0.5908\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.6351 - val_loss: 0.5809\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.5553 - val_loss: 0.5725\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.5592 - val_loss: 0.5634\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.5794 - val_loss: 0.5552\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.5687 - val_loss: 0.5488\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.5448 - val_loss: 0.5409\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.5435 - val_loss: 0.5337\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.5419 - val_loss: 0.5268\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.5349 - val_loss: 0.5205\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5030 - val_loss: 0.5150\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.5359 - val_loss: 0.5091\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.5329 - val_loss: 0.5050\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.5136 - val_loss: 0.4991\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.5150 - val_loss: 0.4955\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4816 - val_loss: 0.4904\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.5140 - val_loss: 0.4859\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4971 - val_loss: 0.4833\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4921 - val_loss: 0.4785\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4704 - val_loss: 0.4748\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4948 - val_loss: 0.4719\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4725 - val_loss: 0.4680\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4626 - val_loss: 0.4648\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4600 - val_loss: 0.4613\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4611 - val_loss: 0.4587\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4808 - val_loss: 0.4564\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 772us/step - loss: 0.4623 - val_loss: 0.4541\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4599 - val_loss: 0.4517\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4611 - val_loss: 0.4495\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4624 - val_loss: 0.4471\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4447 - val_loss: 0.4456\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4647 - val_loss: 0.4424\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4342 - val_loss: 0.4408\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4517 - val_loss: 0.4383\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.4414 - val_loss: 0.4367\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4448 - val_loss: 0.4354\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4417 - val_loss: 0.4336\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4635 - val_loss: 0.4322\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4202 - val_loss: 0.4301\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4382 - val_loss: 0.4283\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4361 - val_loss: 0.4268\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4598 - val_loss: 0.4252\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4229 - val_loss: 0.4237\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4500 - val_loss: 0.4225\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4167 - val_loss: 0.4207\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4380 - val_loss: 0.4200\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.4266 - val_loss: 0.4189\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4213 - val_loss: 0.4177\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4403 - val_loss: 0.4168\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4397 - val_loss: 0.4163\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4316 - val_loss: 0.4145\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4073 - val_loss: 0.4131\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4122\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4230 - val_loss: 0.4107\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4242 - val_loss: 0.4097\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4133 - val_loss: 0.4090\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4185 - val_loss: 0.4076\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4055 - val_loss: 0.4072\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4095 - val_loss: 0.4062\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4198 - val_loss: 0.4052\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4037 - val_loss: 0.4036\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4321 - val_loss: 0.4031\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4266 - val_loss: 0.4021\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4279 - val_loss: 0.4018\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3917 - val_loss: 0.4006\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4249 - val_loss: 0.3998\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4131 - val_loss: 0.3990\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4019 - val_loss: 0.3985\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4208 - val_loss: 0.3977\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4164 - val_loss: 0.3970\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4104 - val_loss: 0.3966\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4097 - val_loss: 0.3953\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4081 - val_loss: 0.3945\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4108 - val_loss: 0.3940\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3814 - val_loss: 0.3929\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3954 - val_loss: 0.3923\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4119 - val_loss: 0.3919\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.4252 - val_loss: 0.3911\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4144 - val_loss: 0.3908\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4241 - val_loss: 0.3903\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3894\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.3946 - val_loss: 0.3890\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3895 - val_loss: 0.3882\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3999 - val_loss: 0.3878\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3997 - val_loss: 0.3872\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3972 - val_loss: 0.3869\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3856 - val_loss: 0.3863\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3913 - val_loss: 0.3855\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4201 - val_loss: 0.3850\n",
      "121/121 [==============================] - 0s 431us/step - loss: 0.4316\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9468 - val_loss: 1.6640\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 1.4531 - val_loss: 0.9778\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.9344 - val_loss: 0.7958\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.7809 - val_loss: 0.7308\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.7700 - val_loss: 0.7004\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.7194 - val_loss: 0.6784\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.6938 - val_loss: 0.6617\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.6679 - val_loss: 0.6463\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.6599 - val_loss: 0.6315\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.6932 - val_loss: 0.6190\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.6580 - val_loss: 0.6092\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.6200 - val_loss: 0.5981\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.6074 - val_loss: 0.5875\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.5985 - val_loss: 0.5779\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.6118 - val_loss: 0.5692\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 928us/step - loss: 0.5774 - val_loss: 0.5626\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.5750 - val_loss: 0.5538\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.5658 - val_loss: 0.5449\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5693 - val_loss: 0.5402\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.5691 - val_loss: 0.5322\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5402 - val_loss: 0.5271\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.5475 - val_loss: 0.5222\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.5259 - val_loss: 0.5154\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.5364 - val_loss: 0.5102\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.5318 - val_loss: 0.5068\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.5302 - val_loss: 0.5009\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5404 - val_loss: 0.4982\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4992 - val_loss: 0.4930\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.4990 - val_loss: 0.4897\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.4868\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4975 - val_loss: 0.4834\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5067 - val_loss: 0.4805\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4984 - val_loss: 0.4783\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4954 - val_loss: 0.4735\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.5012 - val_loss: 0.4717\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4823 - val_loss: 0.4686\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4740 - val_loss: 0.4659\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4852 - val_loss: 0.4645\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4904 - val_loss: 0.4618\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.4833 - val_loss: 0.4586\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4664 - val_loss: 0.4581\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.4666 - val_loss: 0.4546\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.4537\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4612 - val_loss: 0.4508\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4470 - val_loss: 0.4496\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4544 - val_loss: 0.4494\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4508 - val_loss: 0.4467\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4806 - val_loss: 0.4442\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4663 - val_loss: 0.4422\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4504 - val_loss: 0.4415\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4639 - val_loss: 0.4386\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4478 - val_loss: 0.4374\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4617 - val_loss: 0.4359\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4592 - val_loss: 0.4342\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4496 - val_loss: 0.4332\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4655 - val_loss: 0.4328\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4564 - val_loss: 0.4316\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4444 - val_loss: 0.4306\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4520 - val_loss: 0.4286\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4420 - val_loss: 0.4271\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4382 - val_loss: 0.4259\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.4354 - val_loss: 0.4252\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4586 - val_loss: 0.4233\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.4417 - val_loss: 0.4221\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4522 - val_loss: 0.4215\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4333 - val_loss: 0.4202\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4520 - val_loss: 0.4195\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4449 - val_loss: 0.4186\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4440 - val_loss: 0.4170\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4097 - val_loss: 0.4158\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4067 - val_loss: 0.4151\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4376 - val_loss: 0.4139\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4306 - val_loss: 0.4132\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4411 - val_loss: 0.4120\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4113 - val_loss: 0.4113\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4245 - val_loss: 0.4115\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4158 - val_loss: 0.4099\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.4140 - val_loss: 0.4085\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4135 - val_loss: 0.4085\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4390 - val_loss: 0.4069\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4295 - val_loss: 0.4067\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4199 - val_loss: 0.4057\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.4349 - val_loss: 0.4046\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4150 - val_loss: 0.4034\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4189 - val_loss: 0.4041\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4076 - val_loss: 0.4022\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3984 - val_loss: 0.4017\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4184 - val_loss: 0.4013\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4337 - val_loss: 0.4009\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.4041 - val_loss: 0.4000\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3900 - val_loss: 0.3990\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.3916 - val_loss: 0.3985\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4141 - val_loss: 0.3981\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.3982 - val_loss: 0.3965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4274 - val_loss: 0.3958\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4253 - val_loss: 0.3953\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4272 - val_loss: 0.3952\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3990 - val_loss: 0.3950\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4058 - val_loss: 0.3937\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.4175 - val_loss: 0.3929\n",
      "121/121 [==============================] - 0s 430us/step - loss: 0.4226\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.4292 - val_loss: 1.8095\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 1.5446 - val_loss: 1.0105\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.9319 - val_loss: 0.7954\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.7750 - val_loss: 0.7279\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.7516 - val_loss: 0.6921\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.6892 - val_loss: 0.6692\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.7162 - val_loss: 0.6491\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.6785 - val_loss: 0.6328\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.6715 - val_loss: 0.6166\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.6605 - val_loss: 0.6032\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.6210 - val_loss: 0.5920\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.6308 - val_loss: 0.5802\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5930 - val_loss: 0.5703\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.6122 - val_loss: 0.5598\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5996 - val_loss: 0.5495\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.5954 - val_loss: 0.5416\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.5569 - val_loss: 0.5332\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.5421 - val_loss: 0.5243\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5769 - val_loss: 0.5166\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.5607 - val_loss: 0.5097\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.5291 - val_loss: 0.5040\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5302 - val_loss: 0.4980\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.5238 - val_loss: 0.4924\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.5245 - val_loss: 0.4877\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.5092 - val_loss: 0.4827\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5269 - val_loss: 0.4778\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.5316 - val_loss: 0.4753\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.5175 - val_loss: 0.4703\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4946 - val_loss: 0.4666\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.5065 - val_loss: 0.4633\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4828 - val_loss: 0.4598\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.5205 - val_loss: 0.4573\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.5060 - val_loss: 0.4544\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.4751 - val_loss: 0.4525\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4779 - val_loss: 0.4501\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4766 - val_loss: 0.4463\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4633 - val_loss: 0.4443\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4688 - val_loss: 0.4434\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4839 - val_loss: 0.4400\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4781 - val_loss: 0.4382\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4611 - val_loss: 0.4360\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4635 - val_loss: 0.4349\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4773 - val_loss: 0.4331\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4630 - val_loss: 0.4309\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4578 - val_loss: 0.4294\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4823 - val_loss: 0.4275\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.452 - 0s 754us/step - loss: 0.4530 - val_loss: 0.4261\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4593 - val_loss: 0.4247\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4232\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4690 - val_loss: 0.4215\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4503 - val_loss: 0.4203\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4529 - val_loss: 0.4192\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4463 - val_loss: 0.4182\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4570 - val_loss: 0.4161\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4506 - val_loss: 0.4153\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4313 - val_loss: 0.4147\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4373 - val_loss: 0.4129\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4329 - val_loss: 0.4128\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4439 - val_loss: 0.4107\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4325 - val_loss: 0.4101\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4291 - val_loss: 0.4093\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4392 - val_loss: 0.4073\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4231 - val_loss: 0.4067\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4299 - val_loss: 0.4061\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4291 - val_loss: 0.4039\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4199 - val_loss: 0.4045\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4347 - val_loss: 0.4024\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4139 - val_loss: 0.4018\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4401 - val_loss: 0.4012\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4436 - val_loss: 0.4007\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4258 - val_loss: 0.3995\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4352 - val_loss: 0.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.4391 - val_loss: 0.3982\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4374 - val_loss: 0.3977\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4157 - val_loss: 0.3972\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4024 - val_loss: 0.3960\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4406 - val_loss: 0.3950\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.4249 - val_loss: 0.3945\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.4123 - val_loss: 0.3942\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4198 - val_loss: 0.3935\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4206 - val_loss: 0.3923\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.3824 - val_loss: 0.3919\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4140 - val_loss: 0.3911\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4259 - val_loss: 0.3905\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4207 - val_loss: 0.3901\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4191 - val_loss: 0.3893\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4164 - val_loss: 0.3885\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4076 - val_loss: 0.3881\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4104 - val_loss: 0.3884\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4060 - val_loss: 0.3868\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4156 - val_loss: 0.3864\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4194 - val_loss: 0.3858\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3946 - val_loss: 0.3858\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3993 - val_loss: 0.3849\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3894 - val_loss: 0.3845\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3979 - val_loss: 0.3840\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4203 - val_loss: 0.3838\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4001 - val_loss: 0.3829\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4154 - val_loss: 0.3823\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4058 - val_loss: 0.3822\n",
      "121/121 [==============================] - 0s 359us/step - loss: 0.3859\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0816 - val_loss: 0.5388\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4970 - val_loss: 0.4378\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4337 - val_loss: 0.5409\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4850 - val_loss: 0.5875\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4896 - val_loss: 0.9409\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4233 - val_loss: 0.9474\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4564 - val_loss: 0.4522\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4110 - val_loss: 0.3929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4066 - val_loss: 0.4149\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3898 - val_loss: 0.3916\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.3861 - val_loss: 0.3636\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3492 - val_loss: 0.3589\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3791 - val_loss: 0.3574\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3489 - val_loss: 0.3480\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3580 - val_loss: 0.3521\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3754 - val_loss: 0.3462\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3449 - val_loss: 0.3398\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3496 - val_loss: 0.3527\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.3497 - val_loss: 0.3575\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.3484 - val_loss: 0.3387\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3625 - val_loss: 0.3272\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.3317 - val_loss: 0.3509\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3439 - val_loss: 0.3350\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3466 - val_loss: 0.3299\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3374 - val_loss: 0.3310\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3364 - val_loss: 0.3244\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3348 - val_loss: 0.3482\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3148 - val_loss: 0.3366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3271 - val_loss: 0.3365\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3327 - val_loss: 0.3376\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3195\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3290 - val_loss: 0.3185\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3275 - val_loss: 0.3196\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.3181 - val_loss: 0.3204\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3310 - val_loss: 0.3185\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.3157 - val_loss: 0.3158\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3244 - val_loss: 0.3333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3256 - val_loss: 0.3393\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3195 - val_loss: 0.3530\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3195 - val_loss: 0.3643\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3220 - val_loss: 0.3825\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3084 - val_loss: 0.3226\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3263 - val_loss: 0.3317\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3115 - val_loss: 0.3133\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3153 - val_loss: 0.3267\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3085 - val_loss: 0.3042\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3223 - val_loss: 0.3313\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3148 - val_loss: 0.3075\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3196 - val_loss: 0.3221\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.3176 - val_loss: 0.3093\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 736us/step - loss: 0.3172 - val_loss: 0.3083\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3137 - val_loss: 0.3039\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3146 - val_loss: 0.3247\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3051 - val_loss: 0.3071\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3089 - val_loss: 0.3206\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3014 - val_loss: 0.3065\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3048 - val_loss: 0.3437\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.2982 - val_loss: 0.3071\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3005 - val_loss: 0.3912\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3084 - val_loss: 0.4254\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3189 - val_loss: 0.4135\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3158 - val_loss: 0.3048\n",
      "121/121 [==============================] - 0s 382us/step - loss: 0.3372\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1926 - val_loss: 0.6568\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.5982 - val_loss: 0.4222\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4375 - val_loss: 0.3844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4086 - val_loss: 0.3770\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3871 - val_loss: 0.3608\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3736 - val_loss: 0.3614\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.4247 - val_loss: 0.3526\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3818 - val_loss: 0.3609\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3832 - val_loss: 0.3620\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3586 - val_loss: 0.3429\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3636 - val_loss: 0.3526\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3793 - val_loss: 0.3508\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3713 - val_loss: 0.3357\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3396 - val_loss: 0.3323\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3684 - val_loss: 0.3341\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3374 - val_loss: 0.3254\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3354 - val_loss: 0.3351\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3335 - val_loss: 0.3251\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3341 - val_loss: 0.3421\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3245 - val_loss: 0.3196\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3221 - val_loss: 0.3423\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3147\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3344 - val_loss: 0.3264\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3176 - val_loss: 0.3228\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3153 - val_loss: 0.3198\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3200 - val_loss: 0.3476\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3233 - val_loss: 0.3204\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3220 - val_loss: 0.3101\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3295 - val_loss: 0.3043\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.3107 - val_loss: 0.3045\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3192 - val_loss: 0.3016\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3219 - val_loss: 0.3019\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3148 - val_loss: 0.3115\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3139 - val_loss: 0.3041\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.3122 - val_loss: 0.3068\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3188 - val_loss: 0.2976\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3248 - val_loss: 0.3036\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3134 - val_loss: 0.3025\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3026 - val_loss: 0.3470\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3205 - val_loss: 0.3430\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3088 - val_loss: 0.3179\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.318 - 0s 732us/step - loss: 0.3176 - val_loss: 0.3051\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3093 - val_loss: 0.3138\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3211 - val_loss: 0.3065\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3025 - val_loss: 0.3148\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.2990 - val_loss: 0.3177\n",
      "121/121 [==============================] - 0s 390us/step - loss: 0.3582\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.3164 - val_loss: 7.7887\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.6335 - val_loss: 18.7110\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.6533 - val_loss: 0.6154\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.9828 - val_loss: 0.3833\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3853 - val_loss: 0.3666\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.3744 - val_loss: 0.4872\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3976 - val_loss: 0.3738\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3694 - val_loss: 0.3511\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3736 - val_loss: 0.3887\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3694 - val_loss: 0.3702\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3767 - val_loss: 0.3488\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3723 - val_loss: 0.4550\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3847 - val_loss: 0.3345\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3492 - val_loss: 0.3353\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3440 - val_loss: 0.3359\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3485 - val_loss: 0.3244\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3485 - val_loss: 0.3489\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3361 - val_loss: 0.3231\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3528 - val_loss: 0.3399\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 766us/step - loss: 0.3790 - val_loss: 0.3363\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.3529 - val_loss: 0.3357\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4031 - val_loss: 0.3369\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3547 - val_loss: 0.3229\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3291 - val_loss: 0.3307\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3516 - val_loss: 0.3202\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3303 - val_loss: 0.3261\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3156 - val_loss: 0.3268\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3421 - val_loss: 0.3591\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3675 - val_loss: 0.3157\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3449 - val_loss: 0.3278\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3350 - val_loss: 0.3255\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3509 - val_loss: 0.3186\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3226 - val_loss: 0.3204\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3544 - val_loss: 0.3147\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3205 - val_loss: 0.3200\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3244 - val_loss: 0.3110\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3219 - val_loss: 0.3149\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3235 - val_loss: 0.3184\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3252 - val_loss: 0.3159\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3287 - val_loss: 0.3222\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3276 - val_loss: 0.3130\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3315 - val_loss: 0.3140\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3380 - val_loss: 0.3146\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3295 - val_loss: 0.3120\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3342 - val_loss: 0.3217\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3228 - val_loss: 0.3543\n",
      "121/121 [==============================] - 0s 482us/step - loss: 0.3975\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0970 - val_loss: 0.8359\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.5267 - val_loss: 0.6979\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4863 - val_loss: 0.4253\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4721 - val_loss: 0.4395\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4319 - val_loss: 0.3976\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3983 - val_loss: 0.3862\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3908 - val_loss: 0.3942\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3955 - val_loss: 0.3869\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.3810 - val_loss: 0.3765\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.3946 - val_loss: 0.3655\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3838 - val_loss: 0.3588\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3572 - val_loss: 0.3607\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3661 - val_loss: 0.3607\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3725 - val_loss: 0.3566\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3595 - val_loss: 0.3773\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3817 - val_loss: 0.3482\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3493 - val_loss: 0.3541\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3591 - val_loss: 0.3498\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.4455 - val_loss: 0.3860\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3879 - val_loss: 0.3754\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3979 - val_loss: 0.3722\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3662 - val_loss: 0.3597\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3725 - val_loss: 0.3571\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3610 - val_loss: 0.3494\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3564 - val_loss: 0.3496\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3616 - val_loss: 0.3433\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3513 - val_loss: 0.3444\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.3457 - val_loss: 0.3474\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3566 - val_loss: 0.3721\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3387 - val_loss: 0.3691\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3477 - val_loss: 0.4479\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3594 - val_loss: 0.4980\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3452 - val_loss: 0.4707\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3613 - val_loss: 0.4008\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3491 - val_loss: 0.3797\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3569 - val_loss: 0.3451\n",
      "121/121 [==============================] - 0s 413us/step - loss: 0.3800\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.8538 - val_loss: 7.4264\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 446us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4459 - val_loss: 1.0844\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 1.7242 - val_loss: 0.5002\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.6308 - val_loss: 2.8049\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 832us/step - loss: 1.5147 - val_loss: 0.5029\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4468 - val_loss: 5.1206\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.5497 - val_loss: 17.7278\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 450us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.9003 - val_loss: 0.8892\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.4299 - val_loss: 0.4129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.3896 - val_loss: 0.4213\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3729 - val_loss: 0.3691\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3796 - val_loss: 0.3716\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3659 - val_loss: 0.3546\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3825 - val_loss: 0.3548\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3201 - val_loss: 0.3421\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3357 - val_loss: 0.3555\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3224 - val_loss: 0.3494\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.3396 - val_loss: 0.3117\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.3092 - val_loss: 0.3381\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.3078 - val_loss: 0.3240\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.3337 - val_loss: 0.3359\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.3165 - val_loss: 0.3110\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3080 - val_loss: 0.3459\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.2955 - val_loss: 0.3910\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3604 - val_loss: 0.4096\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.2980 - val_loss: 0.3144\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.2913 - val_loss: 0.2982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2762 - val_loss: 0.2938\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.2917 - val_loss: 0.3229\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3074 - val_loss: 0.2866\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2695 - val_loss: 0.2950\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.2838 - val_loss: 0.2857\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2738 - val_loss: 0.3283\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.2740 - val_loss: 0.3219\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2777 - val_loss: 0.2851\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.2823 - val_loss: 0.2972\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.2886 - val_loss: 0.2956\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.2796 - val_loss: 0.2899\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2745 - val_loss: 0.2940\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.2768 - val_loss: 0.2943\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.2768 - val_loss: 0.2805\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.2891 - val_loss: 0.2822\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2779 - val_loss: 0.2897\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.2767 - val_loss: 0.2851\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.2837 - val_loss: 0.3037\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3006 - val_loss: 0.2796\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.2775 - val_loss: 0.2958\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2672 - val_loss: 0.2858\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2473 - val_loss: 0.2721\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.2923 - val_loss: 0.2930\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2677 - val_loss: 0.2867\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.262 - 0s 791us/step - loss: 0.2645 - val_loss: 0.2822\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.2600 - val_loss: 0.2837\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.2736 - val_loss: 0.2739\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.2614 - val_loss: 0.2818\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2528 - val_loss: 0.2783\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.2629 - val_loss: 0.2961\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.2688 - val_loss: 0.2906\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.2714\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.2686 - val_loss: 0.2966\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.2817 - val_loss: 0.2776\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.2581 - val_loss: 0.2807\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2700 - val_loss: 0.2699\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2657 - val_loss: 0.2797\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2554 - val_loss: 0.2898\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.2571 - val_loss: 0.2743\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.2592 - val_loss: 0.2822\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2749 - val_loss: 0.2831\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.2391 - val_loss: 0.2810\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2587 - val_loss: 0.2958\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.2715 - val_loss: 0.2738\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.2546 - val_loss: 0.2962\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.245 - 0s 791us/step - loss: 0.2465 - val_loss: 0.2842\n",
      "121/121 [==============================] - 0s 441us/step - loss: 0.3077\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1130 - val_loss: 0.6050\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.6463 - val_loss: 0.8221\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 824us/step - loss: 0.4592 - val_loss: 0.3730\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3686 - val_loss: 0.3501\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.3534 - val_loss: 0.3182\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3393 - val_loss: 0.3231\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.3437 - val_loss: 0.3168\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3325 - val_loss: 0.3105\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3162 - val_loss: 0.2979\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3032\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3152 - val_loss: 0.3029\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3192 - val_loss: 0.3033\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.3127 - val_loss: 0.2912\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.3116 - val_loss: 0.3127\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.2944 - val_loss: 0.3007\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.2964 - val_loss: 0.2947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3104 - val_loss: 0.2931\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3121 - val_loss: 0.2872\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3029 - val_loss: 0.2898\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3047 - val_loss: 0.2886\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2971 - val_loss: 0.2953\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.2871 - val_loss: 0.2850\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.2966 - val_loss: 0.3012\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.2710 - val_loss: 0.3079\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.2975 - val_loss: 0.3188\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2822 - val_loss: 0.2876\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.2936 - val_loss: 0.2888\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3027 - val_loss: 0.2762\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3030 - val_loss: 0.2836\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.2883 - val_loss: 0.2816\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.2789 - val_loss: 0.2762\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.2910 - val_loss: 0.2833\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.2719 - val_loss: 0.2746\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.2835 - val_loss: 0.2716\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.2847 - val_loss: 0.2825\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.2936\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.2694 - val_loss: 0.2752\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2703 - val_loss: 0.2756\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2781 - val_loss: 0.2700\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.2716 - val_loss: 0.2723\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.2718 - val_loss: 0.2846\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.2730 - val_loss: 0.2710\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2717 - val_loss: 0.2726\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.2634 - val_loss: 0.2706\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.2690 - val_loss: 0.2726\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.2641 - val_loss: 0.3568\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.2664 - val_loss: 0.2705\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.2675 - val_loss: 0.2667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.2772 - val_loss: 0.2703\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2699 - val_loss: 0.2725\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2742 - val_loss: 0.2691\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.2670 - val_loss: 0.2790\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.2574 - val_loss: 0.2722\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.2755 - val_loss: 0.2729\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2616 - val_loss: 0.2794\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.2683 - val_loss: 0.2807\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2574 - val_loss: 0.3108\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.2602 - val_loss: 0.2734\n",
      "121/121 [==============================] - 0s 400us/step - loss: 0.3087\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.0855 - val_loss: 0.5145\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4551 - val_loss: 0.5691\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5483 - val_loss: 0.5121\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4304 - val_loss: 0.4188\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.8352 - val_loss: 0.3815\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3960 - val_loss: 0.6529\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.6089 - val_loss: 0.3613\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3790 - val_loss: 0.3432\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3716 - val_loss: 0.3587\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.3524 - val_loss: 0.3211\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3539 - val_loss: 0.3219\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3414 - val_loss: 0.3288\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.3565 - val_loss: 0.3075\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3450 - val_loss: 0.3114\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3157 - val_loss: 0.4083\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3258 - val_loss: 0.3400\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3215 - val_loss: 0.3079\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3249 - val_loss: 0.2964\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3026 - val_loss: 0.2984\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3048 - val_loss: 0.3056\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3198 - val_loss: 0.2970\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3139 - val_loss: 0.2980\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 795us/step - loss: 0.3165 - val_loss: 0.2964\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3061 - val_loss: 0.3002\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3131 - val_loss: 0.3080\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.2838 - val_loss: 0.2859\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.2913 - val_loss: 0.2941\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3024 - val_loss: 0.3055\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.3014\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3193 - val_loss: 0.2844\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3206 - val_loss: 0.2910\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3060 - val_loss: 0.3040\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3047 - val_loss: 0.2946\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.2965 - val_loss: 0.2957\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3031 - val_loss: 0.2822\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2935 - val_loss: 0.2848\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.2936 - val_loss: 0.2817\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.2997 - val_loss: 0.2843\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.2759 - val_loss: 0.2896\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.2778 - val_loss: 0.2849\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.2863 - val_loss: 0.2876\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.2707 - val_loss: 0.2716\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.2878 - val_loss: 0.2778\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2782 - val_loss: 0.3209\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.2856 - val_loss: 0.2829\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.2841 - val_loss: 0.2857\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2765 - val_loss: 0.2853\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.280 - 0s 814us/step - loss: 0.2789 - val_loss: 0.3058\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.2762 - val_loss: 0.2729\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.2738 - val_loss: 0.2870\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.2880 - val_loss: 0.2792\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.2773 - val_loss: 0.2893\n",
      "121/121 [==============================] - 0s 413us/step - loss: 0.2831\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2447 - val_loss: 0.6905\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5725 - val_loss: 0.4376\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4333 - val_loss: 0.4148\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4020 - val_loss: 0.3997\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3987 - val_loss: 0.3710\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3913 - val_loss: 0.3815\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3694 - val_loss: 0.3590\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.3431 - val_loss: 0.3415\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3422 - val_loss: 0.3349\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.3331 - val_loss: 0.3494\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3383 - val_loss: 0.3216\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3233 - val_loss: 0.3407\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.3379 - val_loss: 0.3197\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3115 - val_loss: 0.3247\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.3175 - val_loss: 0.3111\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3375 - val_loss: 0.3065\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3208 - val_loss: 0.3304\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3171\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.2994 - val_loss: 0.3311\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.2937 - val_loss: 0.3129\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3176 - val_loss: 0.2980\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3041 - val_loss: 0.3116\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2933 - val_loss: 0.2958\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3048 - val_loss: 0.3222\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.2932 - val_loss: 0.2882\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.2830 - val_loss: 0.2967\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.2940\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2903 - val_loss: 0.3055\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.2804 - val_loss: 0.3054\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.2800 - val_loss: 0.3320\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2906 - val_loss: 0.3017\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.3023 - val_loss: 0.2868\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.2855 - val_loss: 0.3052\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.2990 - val_loss: 0.2828\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.2772 - val_loss: 0.2878\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.2686 - val_loss: 0.2970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2737 - val_loss: 0.2794\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2805 - val_loss: 0.2937\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.2793 - val_loss: 0.2804\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.2757 - val_loss: 0.2918\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2831 - val_loss: 0.2862\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.2723 - val_loss: 0.2765\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.2754 - val_loss: 0.2931\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2762 - val_loss: 0.2888\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.2835 - val_loss: 0.2883\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.2758 - val_loss: 0.3329\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2732 - val_loss: 0.2968\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2776 - val_loss: 0.2840\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 800us/step - loss: 0.2704 - val_loss: 0.2916\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.2815 - val_loss: 0.2718\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.2768 - val_loss: 0.2927\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.2796 - val_loss: 0.2788\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.2787 - val_loss: 0.2719\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.2743 - val_loss: 0.2922\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2548 - val_loss: 0.2773\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.2696 - val_loss: 0.2942\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.2857 - val_loss: 0.2876\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2711 - val_loss: 0.2959\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.2904 - val_loss: 0.2839\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2793 - val_loss: 0.2920\n",
      "121/121 [==============================] - 0s 403us/step - loss: 0.3144\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.4182 - val_loss: 0.8117\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.5378 - val_loss: 1.0133\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.6288 - val_loss: 0.4137\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.4372 - val_loss: 0.3890\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.4182 - val_loss: 0.3694\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3843 - val_loss: 0.3664\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3729 - val_loss: 0.3621\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3754 - val_loss: 0.3532\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3499 - val_loss: 0.3470\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3608 - val_loss: 0.3397\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3514 - val_loss: 0.3457\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.3544 - val_loss: 0.3416\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3356 - val_loss: 0.3303\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3229 - val_loss: 0.3552\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3285 - val_loss: 0.3234\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3451 - val_loss: 0.3182\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3349\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3358 - val_loss: 0.3311\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3297 - val_loss: 0.3346\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.3263 - val_loss: 0.3163\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3205 - val_loss: 0.3330\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3152 - val_loss: 0.3103\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3187 - val_loss: 0.3431\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3351 - val_loss: 0.3045\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.3078 - val_loss: 0.3101\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.3154 - val_loss: 0.3038\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.314 - 0s 828us/step - loss: 0.3129 - val_loss: 0.3032\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3083 - val_loss: 0.2983\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3193 - val_loss: 0.2992\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3039 - val_loss: 0.3002\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.2982 - val_loss: 0.2919\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3149 - val_loss: 0.3008\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2826 - val_loss: 0.2896\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.3006 - val_loss: 0.2932\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.3027 - val_loss: 0.3001\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.2887 - val_loss: 0.3050\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.2842 - val_loss: 0.2864\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2863 - val_loss: 0.2851\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.3005 - val_loss: 0.2905\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.2696 - val_loss: 0.3044\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.2747 - val_loss: 0.2863\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.2644 - val_loss: 0.2887\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.2825 - val_loss: 0.2823\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2719 - val_loss: 0.2842\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.2687 - val_loss: 0.2914\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.2722 - val_loss: 0.2958\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.2783 - val_loss: 0.2792\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.2684 - val_loss: 0.2861\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2725 - val_loss: 0.2821\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2745 - val_loss: 0.2800\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2524 - val_loss: 0.2745\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.2818 - val_loss: 0.2846\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2689 - val_loss: 0.2733\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2692 - val_loss: 0.2785\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.2732 - val_loss: 0.2905\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.2766 - val_loss: 0.2845\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2754 - val_loss: 0.2973\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.2628 - val_loss: 0.2740\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.2790 - val_loss: 0.2940\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.2712 - val_loss: 0.2817\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2578 - val_loss: 0.2751\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2616 - val_loss: 0.2901\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.2498 - val_loss: 0.2731\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.2595 - val_loss: 0.2819\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.2707 - val_loss: 0.2730\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2499 - val_loss: 0.3090\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 797us/step - loss: 0.2621 - val_loss: 0.3020\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.2579 - val_loss: 0.2706\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2623 - val_loss: 0.3041\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2471 - val_loss: 0.2723\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2580 - val_loss: 0.2834\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2581 - val_loss: 0.2720\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.2511 - val_loss: 0.2711\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.2580 - val_loss: 0.2854\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.2628 - val_loss: 0.2774\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2619 - val_loss: 0.2770\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.2480 - val_loss: 0.2780\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.2526 - val_loss: 0.3098\n",
      "121/121 [==============================] - 0s 440us/step - loss: 0.3310\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.5747 - val_loss: 1.0939\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.8275 - val_loss: 4.9275\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.8357 - val_loss: 0.4390\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.4735 - val_loss: 0.3824\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.4095 - val_loss: 0.4420\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4155 - val_loss: 1.2089\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5299 - val_loss: 0.3794\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4276 - val_loss: 0.3586\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.3703 - val_loss: 0.3461\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3697 - val_loss: 0.3416\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3543 - val_loss: 0.3473\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3521 - val_loss: 0.3285\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3250\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3587 - val_loss: 0.3190\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3434 - val_loss: 0.3207\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3525 - val_loss: 0.3342\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.3601 - val_loss: 0.3135\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3354 - val_loss: 0.3459\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3416 - val_loss: 0.3791\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3253 - val_loss: 0.3127\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3269 - val_loss: 0.2996\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3262 - val_loss: 0.3048\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3350 - val_loss: 0.2983\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3240 - val_loss: 0.3015\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.3292 - val_loss: 0.3000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3102 - val_loss: 0.2943\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.2985 - val_loss: 0.3196\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.3134 - val_loss: 0.3386\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3104 - val_loss: 0.2937\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3015 - val_loss: 0.2886\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3166 - val_loss: 0.2895\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.2971\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.2938\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.2944 - val_loss: 0.3087\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.3032 - val_loss: 0.2855\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.2942 - val_loss: 0.3012\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3021 - val_loss: 0.2912\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3106 - val_loss: 0.2864\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.2775\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3013 - val_loss: 0.2822\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.2994 - val_loss: 0.2767\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.2862 - val_loss: 0.3026\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3020 - val_loss: 0.2782\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.3003 - val_loss: 0.2813\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.2939 - val_loss: 0.2969\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.2961 - val_loss: 0.2786\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.2727 - val_loss: 0.2791\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.2737 - val_loss: 0.3041\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.2812 - val_loss: 0.2813\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.2810 - val_loss: 0.2777\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.2755 - val_loss: 0.3084\n",
      "121/121 [==============================] - 0s 436us/step - loss: 0.3236\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.2073 - val_loss: 0.9912\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.8222 - val_loss: 0.6805\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.6708 - val_loss: 0.5915\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5899 - val_loss: 0.5493\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5440 - val_loss: 0.5141\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.5314 - val_loss: 0.4892\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4933 - val_loss: 0.4692\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4847 - val_loss: 0.4599\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4955 - val_loss: 0.4476\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4385 - val_loss: 0.4270\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4163\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4399 - val_loss: 0.4070\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4157 - val_loss: 0.3955\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4019 - val_loss: 0.3890\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.3944 - val_loss: 0.3844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3934 - val_loss: 0.3795\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3871 - val_loss: 0.3759\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3648 - val_loss: 0.3715\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3906 - val_loss: 0.3677\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3669 - val_loss: 0.3636\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3794 - val_loss: 0.3611\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3744 - val_loss: 0.3594\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3728 - val_loss: 0.3593\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3639 - val_loss: 0.3574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3559 - val_loss: 0.3539\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3581 - val_loss: 0.3526\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3661 - val_loss: 0.3508\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3569 - val_loss: 0.3511\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3535 - val_loss: 0.3498\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3471\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3541 - val_loss: 0.3445\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3633 - val_loss: 0.3432\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3451 - val_loss: 0.3432\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3400 - val_loss: 0.3441\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3409\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3403\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3450 - val_loss: 0.3406\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3579 - val_loss: 0.3383\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3364 - val_loss: 0.3362\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3557 - val_loss: 0.3362\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3436 - val_loss: 0.3361\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3428 - val_loss: 0.3327\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3397 - val_loss: 0.3338\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3372 - val_loss: 0.3323\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3289 - val_loss: 0.3337\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3336 - val_loss: 0.3305\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3395 - val_loss: 0.3340\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3332 - val_loss: 0.3316\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3441 - val_loss: 0.3274\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3286 - val_loss: 0.3272\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3309 - val_loss: 0.3269\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3439 - val_loss: 0.3270\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3294 - val_loss: 0.3278\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3435 - val_loss: 0.3248\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3275 - val_loss: 0.3245\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3246 - val_loss: 0.3279\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3270 - val_loss: 0.3229\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3317 - val_loss: 0.3228\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3180 - val_loss: 0.3241\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3247\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3432 - val_loss: 0.3203\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3150 - val_loss: 0.3185\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3221 - val_loss: 0.3180\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3247 - val_loss: 0.3220\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3257 - val_loss: 0.3174\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3310 - val_loss: 0.3170\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3265 - val_loss: 0.3176\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3154 - val_loss: 0.3164\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3228 - val_loss: 0.3163\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3228 - val_loss: 0.3144\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3079 - val_loss: 0.3137\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3354 - val_loss: 0.3171\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3335 - val_loss: 0.3123\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3211 - val_loss: 0.3144\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3397 - val_loss: 0.3148\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3154 - val_loss: 0.3116\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3183 - val_loss: 0.3166\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3215 - val_loss: 0.3127\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3102\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3113 - val_loss: 0.3111\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3137 - val_loss: 0.3090\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3034 - val_loss: 0.3085\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3010 - val_loss: 0.3081\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3020 - val_loss: 0.3120\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3072\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3027 - val_loss: 0.3054\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3052 - val_loss: 0.3062\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3040 - val_loss: 0.3067\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3008 - val_loss: 0.3038\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.2938 - val_loss: 0.3046\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3008 - val_loss: 0.3088\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3269 - val_loss: 0.3011\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3033 - val_loss: 0.3049\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3043 - val_loss: 0.3020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.2882 - val_loss: 0.3104\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3130 - val_loss: 0.3019\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3010 - val_loss: 0.2999\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3064 - val_loss: 0.2994\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3038 - val_loss: 0.3046\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.2971 - val_loss: 0.3027\n",
      "121/121 [==============================] - 0s 441us/step - loss: 0.3338\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.8935 - val_loss: 0.7756\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.7010 - val_loss: 0.6394\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.6542 - val_loss: 0.5860\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5977 - val_loss: 0.5425\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5638 - val_loss: 0.5107\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5134 - val_loss: 0.4855\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.4623\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4814 - val_loss: 0.4440\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4434 - val_loss: 0.4279\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4559 - val_loss: 0.4188\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4420 - val_loss: 0.4039\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4204 - val_loss: 0.3964\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4103 - val_loss: 0.3868\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4028 - val_loss: 0.3835\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3848 - val_loss: 0.3755\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3932 - val_loss: 0.3730\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3907 - val_loss: 0.3694\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3869 - val_loss: 0.3667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3659 - val_loss: 0.3627\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3570 - val_loss: 0.3607\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3686 - val_loss: 0.3598\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3603 - val_loss: 0.3561\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3729 - val_loss: 0.3535\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3736 - val_loss: 0.3527\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3554 - val_loss: 0.3505\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3609 - val_loss: 0.3488\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3489\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3594 - val_loss: 0.3457\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3473 - val_loss: 0.3450\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3550 - val_loss: 0.3446\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3284 - val_loss: 0.3435\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3457\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3393 - val_loss: 0.3442\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3541 - val_loss: 0.3395\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3548 - val_loss: 0.3401\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3530 - val_loss: 0.3401\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3447 - val_loss: 0.3349\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3492 - val_loss: 0.3381\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3420 - val_loss: 0.3339\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3484 - val_loss: 0.3374\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3488 - val_loss: 0.3331\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3381 - val_loss: 0.3316\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3305 - val_loss: 0.3313\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3333 - val_loss: 0.3304\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3514 - val_loss: 0.3293\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3236 - val_loss: 0.3269\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3123 - val_loss: 0.3279\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3393 - val_loss: 0.3298\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3350 - val_loss: 0.3259\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3288 - val_loss: 0.3243\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3304 - val_loss: 0.3267\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3096 - val_loss: 0.3244\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3245 - val_loss: 0.3234\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3407 - val_loss: 0.3217\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3220 - val_loss: 0.3233\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3259 - val_loss: 0.3202\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3194\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3242 - val_loss: 0.3193\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3204 - val_loss: 0.3194\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3309 - val_loss: 0.3172\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3252 - val_loss: 0.3198\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3223 - val_loss: 0.3151\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3176 - val_loss: 0.3203\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3199 - val_loss: 0.3150\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3183 - val_loss: 0.3207\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3192 - val_loss: 0.3132\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3147 - val_loss: 0.3187\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3143 - val_loss: 0.3156\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3087 - val_loss: 0.3142\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3223 - val_loss: 0.3135\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3225 - val_loss: 0.3139\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3128 - val_loss: 0.3141\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 851us/step - loss: 0.3080 - val_loss: 0.3117\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3013 - val_loss: 0.3130\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3140 - val_loss: 0.3113\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3098\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3122\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3066 - val_loss: 0.3072\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.2933 - val_loss: 0.3154\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3067 - val_loss: 0.3099\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.3080\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3070 - val_loss: 0.3100\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3066 - val_loss: 0.3059\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3115 - val_loss: 0.3077\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3160 - val_loss: 0.3066\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3000 - val_loss: 0.3065\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.2979 - val_loss: 0.3067\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3083 - val_loss: 0.3044\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3092 - val_loss: 0.3065\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3090 - val_loss: 0.3076\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3004 - val_loss: 0.3034\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3079 - val_loss: 0.3066\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3001 - val_loss: 0.3025\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.2886 - val_loss: 0.3040\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3129 - val_loss: 0.3047\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3021 - val_loss: 0.3037\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.2973 - val_loss: 0.3044\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.2906 - val_loss: 0.3016\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.2960 - val_loss: 0.3008\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.2972 - val_loss: 0.3005\n",
      "121/121 [==============================] - 0s 464us/step - loss: 0.3326\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.1698 - val_loss: 0.9003\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.8554 - val_loss: 0.7128\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.7175 - val_loss: 0.6476\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6703 - val_loss: 0.6099\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.6541 - val_loss: 0.5814\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.6183 - val_loss: 0.5559\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.6094 - val_loss: 0.5320\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5602 - val_loss: 0.5109\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.5791 - val_loss: 0.4927\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5351 - val_loss: 0.4769\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5002 - val_loss: 0.4626\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4780 - val_loss: 0.4497\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4771 - val_loss: 0.4373\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4732 - val_loss: 0.4290\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4338 - val_loss: 0.4203\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4544 - val_loss: 0.4113\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4481 - val_loss: 0.4036\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4325 - val_loss: 0.3991\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4308 - val_loss: 0.3921\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4153 - val_loss: 0.3874\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4161 - val_loss: 0.3843\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4042 - val_loss: 0.3795\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.3781\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.398 - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3742\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4074 - val_loss: 0.3705\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3864 - val_loss: 0.3676\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3894 - val_loss: 0.3693\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3650\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3887 - val_loss: 0.3635\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3923 - val_loss: 0.3610\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3547 - val_loss: 0.3592\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3925 - val_loss: 0.3581\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3686 - val_loss: 0.3562\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3916 - val_loss: 0.3534\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3724 - val_loss: 0.3515\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.3882 - val_loss: 0.3539\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3782 - val_loss: 0.3497\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3600 - val_loss: 0.3489\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3493 - val_loss: 0.3473\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3724 - val_loss: 0.3447\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3551 - val_loss: 0.3449\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3758 - val_loss: 0.3427\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3682 - val_loss: 0.3420\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3505 - val_loss: 0.3419\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3767 - val_loss: 0.3399\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3897 - val_loss: 0.3379\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3533 - val_loss: 0.3411\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3568 - val_loss: 0.3357\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3678 - val_loss: 0.3364\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3437 - val_loss: 0.3381\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 923us/step - loss: 0.3582 - val_loss: 0.3343\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3327\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3342 - val_loss: 0.3331\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3613 - val_loss: 0.3307\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3450 - val_loss: 0.3368\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3278 - val_loss: 0.3288\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3216 - val_loss: 0.3303\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3512 - val_loss: 0.3296\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3550 - val_loss: 0.3301\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3487 - val_loss: 0.3331\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3405 - val_loss: 0.3247\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3403 - val_loss: 0.3286\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3422 - val_loss: 0.3238\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3474 - val_loss: 0.3274\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3232 - val_loss: 0.3232\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3287 - val_loss: 0.3262\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3220 - val_loss: 0.3241\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3206 - val_loss: 0.3238\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3371 - val_loss: 0.3213\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3179 - val_loss: 0.3251\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3190\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3269 - val_loss: 0.3221\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3266 - val_loss: 0.3184\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3317 - val_loss: 0.3195\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3179\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3186\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3298 - val_loss: 0.3161\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3378 - val_loss: 0.3199\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3440 - val_loss: 0.3167\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3349 - val_loss: 0.3189\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3341 - val_loss: 0.3155\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3287 - val_loss: 0.3146\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3161 - val_loss: 0.3141\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3261 - val_loss: 0.3137\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3230 - val_loss: 0.3128\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3248 - val_loss: 0.3162\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3270 - val_loss: 0.3106\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3241 - val_loss: 0.3151\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3214 - val_loss: 0.3118\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2955 - val_loss: 0.3127\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3178 - val_loss: 0.3129\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3200 - val_loss: 0.3094\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3180 - val_loss: 0.3182\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3077 - val_loss: 0.3074\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3241 - val_loss: 0.3094\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3168 - val_loss: 0.3156\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3248 - val_loss: 0.3063\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3088 - val_loss: 0.3148\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3146 - val_loss: 0.3050\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.3115\n",
      "121/121 [==============================] - 0s 435us/step - loss: 0.3069\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5235 - val_loss: 0.7169\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.5796 - val_loss: 0.6206\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.5101 - val_loss: 0.5465\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4706 - val_loss: 0.5418\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4498 - val_loss: 0.4489\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4310 - val_loss: 0.4161\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4287 - val_loss: 0.3998\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3943 - val_loss: 0.3966\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3966 - val_loss: 0.3840\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4118 - val_loss: 0.3814\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3985 - val_loss: 0.3746\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3770 - val_loss: 0.3803\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3971 - val_loss: 0.3677\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3783 - val_loss: 0.3721\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3831 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3755 - val_loss: 0.3580\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3719 - val_loss: 0.3561\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3752 - val_loss: 0.3571\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3661 - val_loss: 0.3548\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3796 - val_loss: 0.3587\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3797 - val_loss: 0.4307\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3807 - val_loss: 0.3548\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.3621 - val_loss: 0.3680\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.3575 - val_loss: 0.3430\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3680 - val_loss: 0.3444\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3714 - val_loss: 0.3386\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3558 - val_loss: 0.3545\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4300 - val_loss: 0.3500\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 760us/step - loss: 0.3547 - val_loss: 0.3451\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3753 - val_loss: 0.3428\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3423 - val_loss: 0.3503\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3491 - val_loss: 0.3461\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3390 - val_loss: 0.3385\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3465 - val_loss: 0.3524\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3387 - val_loss: 0.3382\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.3344 - val_loss: 0.3629\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3450 - val_loss: 0.3523\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3487 - val_loss: 0.4204\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3497 - val_loss: 0.4172\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3570 - val_loss: 0.6512\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3381 - val_loss: 0.9165\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4615 - val_loss: 0.9842\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3706 - val_loss: 0.6908\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3479 - val_loss: 0.5503\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3743 - val_loss: 0.3960\n",
      "121/121 [==============================] - 0s 413us/step - loss: 0.4169\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8676 - val_loss: 0.8811\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.8116 - val_loss: 0.5697\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.5745 - val_loss: 0.4666\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4760 - val_loss: 0.4333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.4578 - val_loss: 0.4169\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.4500 - val_loss: 0.4104\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4127 - val_loss: 0.4279\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4169 - val_loss: 0.3901\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4144 - val_loss: 0.3886\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4071 - val_loss: 0.3786\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4053 - val_loss: 0.3751\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4114 - val_loss: 0.3733\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3803 - val_loss: 0.3699\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3745 - val_loss: 0.3674\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4013 - val_loss: 0.3658\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3714 - val_loss: 0.3657\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3678 - val_loss: 0.3617\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3739 - val_loss: 0.3673\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3848 - val_loss: 0.3598\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3729 - val_loss: 0.3551\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3553 - val_loss: 0.3576\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3618 - val_loss: 0.3581\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3681 - val_loss: 0.3778\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3974 - val_loss: 0.3515\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3692 - val_loss: 0.3486\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3766 - val_loss: 0.3515\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3516 - val_loss: 0.3488\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3650 - val_loss: 0.3454\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3857 - val_loss: 0.3445\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3704 - val_loss: 0.3447\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3501 - val_loss: 0.3444\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3476 - val_loss: 0.3443\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3873 - val_loss: 0.3404\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3662 - val_loss: 0.3440\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3702 - val_loss: 0.3617\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3522 - val_loss: 0.3393\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3466 - val_loss: 0.3388\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3426 - val_loss: 0.3376\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3550 - val_loss: 0.3438\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3498 - val_loss: 0.3574\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4385 - val_loss: 0.3363\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3635 - val_loss: 0.3374\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3411 - val_loss: 0.3378\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.3425 - val_loss: 0.3360\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3455 - val_loss: 0.3342\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3463 - val_loss: 0.3343\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3357 - val_loss: 0.3346\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3274 - val_loss: 0.3387\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3381 - val_loss: 0.3331\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3359 - val_loss: 0.3330\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3348 - val_loss: 0.3337\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3309 - val_loss: 0.3306\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3464 - val_loss: 0.3321\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.336 - 0s 774us/step - loss: 0.3368 - val_loss: 0.3358\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3410 - val_loss: 0.3276\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3431 - val_loss: 0.3285\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3213 - val_loss: 0.3336\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3399 - val_loss: 0.3272\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3347 - val_loss: 0.3342\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.3319 - val_loss: 0.3286\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3452 - val_loss: 0.3268\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 792us/step - loss: 0.3618 - val_loss: 0.3245\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3361 - val_loss: 0.3644\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3245 - val_loss: 0.3236\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3259 - val_loss: 0.3301\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3386 - val_loss: 0.3260\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3263 - val_loss: 0.3224\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3409 - val_loss: 0.3229\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3268 - val_loss: 0.3882\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3496 - val_loss: 0.3247\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3172 - val_loss: 0.3258\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3325 - val_loss: 0.3214\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3204 - val_loss: 0.3248\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3350 - val_loss: 0.3204\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3131 - val_loss: 0.3216\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.3179 - val_loss: 0.3242\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3188 - val_loss: 0.3231\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3069 - val_loss: 0.3211\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3342 - val_loss: 0.3188\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3338 - val_loss: 0.3399\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3333 - val_loss: 0.3955\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3477 - val_loss: 0.3205\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3241 - val_loss: 0.3305\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.319 - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3183\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3243 - val_loss: 0.3177\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3387 - val_loss: 0.3174\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3168 - val_loss: 0.3160\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3280 - val_loss: 0.3729\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3202 - val_loss: 0.3157\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3728 - val_loss: 0.3210\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3182 - val_loss: 0.3362\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4028 - val_loss: 0.3141\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3197 - val_loss: 0.3129\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3229 - val_loss: 0.3153\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3179 - val_loss: 0.3122\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3216 - val_loss: 0.3160\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3120 - val_loss: 0.3130\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3131 - val_loss: 0.3148\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3272 - val_loss: 0.3102\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3217 - val_loss: 0.3107\n",
      "121/121 [==============================] - 0s 446us/step - loss: 0.3489\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9109 - val_loss: 6.5969\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.9852 - val_loss: 0.6077\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5554 - val_loss: 0.4331\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4906 - val_loss: 0.4023\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4520 - val_loss: 0.3915\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4001 - val_loss: 0.3677\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4076 - val_loss: 0.3632\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4221 - val_loss: 0.3543\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.3877 - val_loss: 0.3556\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3908 - val_loss: 0.3626\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4140 - val_loss: 0.3504\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3813 - val_loss: 0.3496\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3788 - val_loss: 0.3486\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4278 - val_loss: 0.3487\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.3874 - val_loss: 0.3496\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3675 - val_loss: 0.3456\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3970 - val_loss: 0.3485\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3552 - val_loss: 0.3442\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3662 - val_loss: 0.3438\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.3622 - val_loss: 0.3464\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3938 - val_loss: 0.3406\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3630 - val_loss: 0.3407\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3664 - val_loss: 0.3389\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3841 - val_loss: 0.3488\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.3700 - val_loss: 0.3392\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3746 - val_loss: 0.3382\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3669 - val_loss: 0.3391\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3882 - val_loss: 0.3399\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3734 - val_loss: 0.3332\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3570 - val_loss: 0.3386\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3543 - val_loss: 0.3382\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3653 - val_loss: 0.3340\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3556 - val_loss: 0.3386\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3554 - val_loss: 0.3339\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3519 - val_loss: 0.3346\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3582 - val_loss: 0.3388\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3636 - val_loss: 0.3316\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3292\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 869us/step - loss: 0.3529 - val_loss: 0.3284\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3637 - val_loss: 0.3338\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.3500 - val_loss: 0.3318\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3451 - val_loss: 0.3278\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3577 - val_loss: 0.3278\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3499 - val_loss: 0.3279\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3752 - val_loss: 0.3261\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3361 - val_loss: 0.3262\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.328 - 0s 757us/step - loss: 0.3308 - val_loss: 0.3272\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3360 - val_loss: 0.3673\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3396 - val_loss: 0.3248\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3523 - val_loss: 0.3251\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3478 - val_loss: 0.3239\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3350 - val_loss: 0.3266\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3623 - val_loss: 0.3225\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3426 - val_loss: 0.3261\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3261 - val_loss: 0.3248\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3432 - val_loss: 0.3235\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3411 - val_loss: 0.3216\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3314 - val_loss: 0.3240\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3413 - val_loss: 0.3222\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3448 - val_loss: 0.3225\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3242 - val_loss: 0.3211\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3183 - val_loss: 0.3176\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3242 - val_loss: 0.3193\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3514 - val_loss: 0.3224\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.318 - 0s 743us/step - loss: 0.3207 - val_loss: 0.3234\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3294 - val_loss: 0.3210\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3317 - val_loss: 0.3167\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3327 - val_loss: 0.3291\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3776 - val_loss: 0.3227\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3231\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3334 - val_loss: 0.3245\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3286 - val_loss: 0.3192\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3340 - val_loss: 0.3384\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3875 - val_loss: 0.3271\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3389 - val_loss: 0.3545\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4251 - val_loss: 0.3216\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3589 - val_loss: 0.3224\n",
      "121/121 [==============================] - 0s 403us/step - loss: 0.3170\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.1350 - val_loss: 0.4823\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5003 - val_loss: 0.4192\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4409 - val_loss: 0.3905\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3954 - val_loss: 0.3780\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3650 - val_loss: 0.3677\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3590 - val_loss: 0.3620\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3762 - val_loss: 0.3527\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3351 - val_loss: 0.3447\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3361 - val_loss: 0.3497\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3304 - val_loss: 0.3465\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3286 - val_loss: 0.3475\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3552 - val_loss: 0.3238\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.3240\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3188 - val_loss: 0.3770\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3171 - val_loss: 0.3152\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3161\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3158 - val_loss: 0.3104\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3075 - val_loss: 0.3134\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.2988 - val_loss: 0.3302\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3114 - val_loss: 0.3061\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3016 - val_loss: 0.3096\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2970 - val_loss: 0.3247\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2965 - val_loss: 0.3325\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.2898 - val_loss: 0.3005\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.2982 - val_loss: 0.3074\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.2896 - val_loss: 0.3004\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2791 - val_loss: 0.3142\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3096 - val_loss: 0.2980\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.2900 - val_loss: 0.3131\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.2912 - val_loss: 0.3088\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.2704 - val_loss: 0.3035\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.2892 - val_loss: 0.2997\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.2765 - val_loss: 0.2850\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.2786 - val_loss: 0.3181\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2838 - val_loss: 0.2763\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.2683 - val_loss: 0.3184\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.2641 - val_loss: 0.2938\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.2650 - val_loss: 0.3052\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.2662 - val_loss: 0.3047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.2727 - val_loss: 0.3413\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.2666 - val_loss: 0.2962\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2707 - val_loss: 0.2824\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.2675 - val_loss: 0.3263\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.2710 - val_loss: 0.2850\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.2595 - val_loss: 0.2869\n",
      "121/121 [==============================] - 0s 424us/step - loss: 0.3181\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.7939 - val_loss: 0.5164\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4578 - val_loss: 0.4271\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4244 - val_loss: 0.3905\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3981 - val_loss: 0.3600\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3669 - val_loss: 0.3475\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3800 - val_loss: 0.3327\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3657 - val_loss: 0.3311\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3237 - val_loss: 0.3278\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3237 - val_loss: 0.3170\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3362 - val_loss: 0.3100\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3129 - val_loss: 0.3137\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3230 - val_loss: 0.3070\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3137 - val_loss: 0.3046\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3220 - val_loss: 0.2942\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3093 - val_loss: 0.2996\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.2974\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.2976\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.2943 - val_loss: 0.2931\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3230\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3003 - val_loss: 0.2891\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.2907 - val_loss: 0.2929\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2915 - val_loss: 0.3159\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2856 - val_loss: 0.2927\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.2899 - val_loss: 0.2957\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.2926 - val_loss: 0.3071\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2799 - val_loss: 0.2936\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.2858 - val_loss: 0.3034\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.2774 - val_loss: 0.3030\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.2909 - val_loss: 0.2849\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.2801 - val_loss: 0.2901\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.2776 - val_loss: 0.2824\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.2786 - val_loss: 0.3002\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.2734 - val_loss: 0.3241\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.2731 - val_loss: 0.4280\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.2811 - val_loss: 0.2800\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.282 - 0s 829us/step - loss: 0.2824 - val_loss: 0.2830\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.2812 - val_loss: 0.3085\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.2708 - val_loss: 0.2777\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.2558 - val_loss: 0.2789\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.2745 - val_loss: 0.2980\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2597 - val_loss: 0.2858\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.2800 - val_loss: 0.2809\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.2652 - val_loss: 0.3029\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.2803\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.2598 - val_loss: 0.2863\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.2658 - val_loss: 0.2877\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.2752 - val_loss: 0.2757\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.2660 - val_loss: 0.2812\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.2588 - val_loss: 0.2757\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2671 - val_loss: 0.2900\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2774 - val_loss: 0.2796\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.2610 - val_loss: 0.2710\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.2627 - val_loss: 0.2827\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.2654 - val_loss: 0.2824\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.2815 - val_loss: 0.2751\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.2497 - val_loss: 0.2848\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2594 - val_loss: 0.2965\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.2680 - val_loss: 0.2940\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.2675 - val_loss: 0.2760\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.2478 - val_loss: 0.2846\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.2594 - val_loss: 0.2744\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.2563 - val_loss: 0.2777\n",
      "121/121 [==============================] - 0s 438us/step - loss: 0.3071\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.5621 - val_loss: 0.8467\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7234 - val_loss: 0.5633\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4551\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6035 - val_loss: 0.4047\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3874 - val_loss: 0.3531\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.3715 - val_loss: 0.3561\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3650 - val_loss: 0.3418\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3615 - val_loss: 0.3335\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3459 - val_loss: 0.3328\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 838us/step - loss: 0.3311 - val_loss: 0.3289\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3495 - val_loss: 0.3213\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3574 - val_loss: 0.3203\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3423 - val_loss: 0.3161\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3597 - val_loss: 0.3162\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3261 - val_loss: 0.3273\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3332 - val_loss: 0.3196\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3376 - val_loss: 0.3067\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.3021 - val_loss: 0.3013\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3293 - val_loss: 0.3011\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.3332 - val_loss: 0.3106\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3263 - val_loss: 0.2943\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3195 - val_loss: 0.3123\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3251 - val_loss: 0.2984\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3082 - val_loss: 0.2904\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.2982 - val_loss: 0.2956\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.2949 - val_loss: 0.3319\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3079 - val_loss: 0.2926\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.2986 - val_loss: 0.2894\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3036 - val_loss: 0.2976\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.2948\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.2957 - val_loss: 0.2859\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3010 - val_loss: 0.3025\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3036 - val_loss: 0.2990\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2998 - val_loss: 0.2833\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.2921 - val_loss: 0.2856\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.2791 - val_loss: 0.2798\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.2972 - val_loss: 0.2909\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.2725 - val_loss: 0.2942\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.2861 - val_loss: 0.2934\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.2890 - val_loss: 0.2990\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.2917 - val_loss: 0.3050\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.2736 - val_loss: 0.2782\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.2820 - val_loss: 0.2784\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.2759 - val_loss: 0.3149\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.2816 - val_loss: 0.2848\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.2802 - val_loss: 0.2871\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.2668 - val_loss: 0.2896\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.2827 - val_loss: 0.2929\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2593 - val_loss: 0.2949\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.2842 - val_loss: 0.3072\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2819 - val_loss: 0.2749\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.2795 - val_loss: 0.2794\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.3140\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.2823 - val_loss: 0.2843\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.2741\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.2671 - val_loss: 0.3530\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2660 - val_loss: 0.2970\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2764 - val_loss: 0.2935\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.2741 - val_loss: 0.2967\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.2604 - val_loss: 0.2860\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2645 - val_loss: 0.2775\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2797 - val_loss: 0.2792\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2723 - val_loss: 0.2855\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.2666 - val_loss: 0.2744\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.2446 - val_loss: 0.2781\n",
      "121/121 [==============================] - 0s 415us/step - loss: 0.2810\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8719 - val_loss: 2.2372\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 1.6024 - val_loss: 1.5179\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.9156 - val_loss: 1.2558\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.7730 - val_loss: 1.1126\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.7677 - val_loss: 1.0076\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.7090 - val_loss: 0.9214\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.6665 - val_loss: 0.8524\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.6487 - val_loss: 0.7951\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.6477 - val_loss: 0.7474\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.6377 - val_loss: 0.7081\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.6081 - val_loss: 0.6754\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.6141 - val_loss: 0.6480\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.5908 - val_loss: 0.6247\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5929 - val_loss: 0.6050\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5873 - val_loss: 0.5877\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5917 - val_loss: 0.5728\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5540 - val_loss: 0.5599\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.5586 - val_loss: 0.5490\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5183 - val_loss: 0.5392\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.5420 - val_loss: 0.5304\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.5419 - val_loss: 0.5230\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.5316 - val_loss: 0.5162\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 779us/step - loss: 0.5308 - val_loss: 0.5102\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.5252 - val_loss: 0.5049\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5117 - val_loss: 0.4998\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4757 - val_loss: 0.4952\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4961 - val_loss: 0.4907\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.5205 - val_loss: 0.4869\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4936 - val_loss: 0.4834\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4970 - val_loss: 0.4800\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4930 - val_loss: 0.4766\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4757 - val_loss: 0.4736\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4651 - val_loss: 0.4709\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.4687 - val_loss: 0.4680\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4861 - val_loss: 0.4656\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4595 - val_loss: 0.4629\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4954 - val_loss: 0.4608\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.4698 - val_loss: 0.4585\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4605 - val_loss: 0.4562\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4839 - val_loss: 0.4542\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4643 - val_loss: 0.4520\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4606 - val_loss: 0.4498\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4646 - val_loss: 0.4483\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4696 - val_loss: 0.4464\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4472 - val_loss: 0.4446\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4614 - val_loss: 0.4431\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4508 - val_loss: 0.4413\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.4431 - val_loss: 0.4398\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.4547 - val_loss: 0.4384\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4578 - val_loss: 0.4368\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4295 - val_loss: 0.4354\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4674 - val_loss: 0.4341\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4409 - val_loss: 0.4328\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.4450 - val_loss: 0.4313\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4409 - val_loss: 0.4301\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4513 - val_loss: 0.4288\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4375 - val_loss: 0.4276\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.4391 - val_loss: 0.4265\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4418 - val_loss: 0.4252\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4271 - val_loss: 0.4243\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4362 - val_loss: 0.4231\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4432 - val_loss: 0.4220\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4406 - val_loss: 0.4209\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4131 - val_loss: 0.4198\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4367 - val_loss: 0.4186\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4439 - val_loss: 0.4177\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4209 - val_loss: 0.4168\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4067 - val_loss: 0.4160\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4190 - val_loss: 0.4151\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4381 - val_loss: 0.4142\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4398 - val_loss: 0.4134\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4018 - val_loss: 0.4124\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4416 - val_loss: 0.4117\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4118 - val_loss: 0.4107\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4080 - val_loss: 0.4098\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4274 - val_loss: 0.4091\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4223 - val_loss: 0.4084\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4195 - val_loss: 0.4074\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4179 - val_loss: 0.4070\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4152 - val_loss: 0.4063\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4295 - val_loss: 0.4055\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4115 - val_loss: 0.4047\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4094 - val_loss: 0.4040\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3944 - val_loss: 0.4033\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4223 - val_loss: 0.4026\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4052 - val_loss: 0.4021\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4079 - val_loss: 0.4013\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4211 - val_loss: 0.4008\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4022 - val_loss: 0.4004\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.4196 - val_loss: 0.3998\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4296 - val_loss: 0.3991\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4115 - val_loss: 0.3988\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3888 - val_loss: 0.3982\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3968 - val_loss: 0.3977\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3894 - val_loss: 0.3970\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4126 - val_loss: 0.3966\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3984 - val_loss: 0.3958\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3923 - val_loss: 0.3955\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3942 - val_loss: 0.3949\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4005 - val_loss: 0.3944\n",
      "121/121 [==============================] - 0s 382us/step - loss: 0.4367\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0276 - val_loss: 2.2165\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 1.6867 - val_loss: 1.1542\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 1.0122 - val_loss: 0.8450\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.7874 - val_loss: 0.7331\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.6975 - val_loss: 0.6802\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.6794 - val_loss: 0.6488\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.6731 - val_loss: 0.6262\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.6500 - val_loss: 0.6083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.6263 - val_loss: 0.5944\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5972 - val_loss: 0.5839\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.6136 - val_loss: 0.5741\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.6097 - val_loss: 0.5632\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.5833 - val_loss: 0.5557\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5696 - val_loss: 0.5461\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.5770 - val_loss: 0.5412\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.5580 - val_loss: 0.5334\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.5368 - val_loss: 0.5275\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5475 - val_loss: 0.5232\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.5462 - val_loss: 0.5169\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5538 - val_loss: 0.5124\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5375 - val_loss: 0.5085\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.5325 - val_loss: 0.5036\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5218 - val_loss: 0.5013\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.4976\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.5187 - val_loss: 0.4936\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.5339 - val_loss: 0.4909\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.5320 - val_loss: 0.4881\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4993 - val_loss: 0.4842\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4702 - val_loss: 0.4811\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4871 - val_loss: 0.4787\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4971 - val_loss: 0.4766\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.5046 - val_loss: 0.4746\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.5104 - val_loss: 0.4730\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.5183 - val_loss: 0.4711\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.5108 - val_loss: 0.4684\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4784 - val_loss: 0.4663\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4956 - val_loss: 0.4646\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4755 - val_loss: 0.4628\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.4834 - val_loss: 0.4601\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4767 - val_loss: 0.4578\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4703 - val_loss: 0.4573\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4759 - val_loss: 0.4558\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4939 - val_loss: 0.4529\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4645 - val_loss: 0.4515\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4528 - val_loss: 0.4509\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4541 - val_loss: 0.4502\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4763 - val_loss: 0.4479\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4528 - val_loss: 0.4463\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4552 - val_loss: 0.4455\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4438\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4578 - val_loss: 0.4416\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4829 - val_loss: 0.4409\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4543 - val_loss: 0.4398\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4587 - val_loss: 0.4388\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4446 - val_loss: 0.4370\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4700 - val_loss: 0.4361\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4669 - val_loss: 0.4355\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4362 - val_loss: 0.4337\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4395 - val_loss: 0.4332\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4411 - val_loss: 0.4325\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4472 - val_loss: 0.4314\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4636 - val_loss: 0.4301\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4524 - val_loss: 0.4294\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4556 - val_loss: 0.4277\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.4448 - val_loss: 0.4269\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4502 - val_loss: 0.4260\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4570 - val_loss: 0.4255\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.4692 - val_loss: 0.4247\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4575 - val_loss: 0.4235\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4444 - val_loss: 0.4227\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4305 - val_loss: 0.4218\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4236 - val_loss: 0.4214\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4262 - val_loss: 0.4204\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4437 - val_loss: 0.4193\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.4349 - val_loss: 0.4190\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4281 - val_loss: 0.4179\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4317 - val_loss: 0.4177\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4169\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4413 - val_loss: 0.4155\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 723us/step - loss: 0.4199 - val_loss: 0.4156\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4235 - val_loss: 0.4141\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4148 - val_loss: 0.4137\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.4567 - val_loss: 0.4129\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4082 - val_loss: 0.4122\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4443 - val_loss: 0.4110\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.4332 - val_loss: 0.4109\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4424 - val_loss: 0.4105\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4563 - val_loss: 0.4093\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.4222 - val_loss: 0.4092\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4164 - val_loss: 0.4087\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4269 - val_loss: 0.4076\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4162 - val_loss: 0.4068\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.4082 - val_loss: 0.4067\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4226 - val_loss: 0.4063\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4158 - val_loss: 0.4057\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4207 - val_loss: 0.4052\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4239 - val_loss: 0.4050\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3940 - val_loss: 0.4040\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4309 - val_loss: 0.4029\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4175 - val_loss: 0.4029\n",
      "121/121 [==============================] - 0s 407us/step - loss: 0.4397\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5254 - val_loss: 2.5593\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 1.9121 - val_loss: 1.3340\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 1.0804 - val_loss: 0.8792\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7994 - val_loss: 0.7029\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.6759 - val_loss: 0.6327\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.6102 - val_loss: 0.5982\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5987 - val_loss: 0.5787\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.6148 - val_loss: 0.5647\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.5886 - val_loss: 0.5540\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.5721 - val_loss: 0.5456\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.5692 - val_loss: 0.5376\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.5727 - val_loss: 0.5307\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.5614 - val_loss: 0.5244\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.5225 - val_loss: 0.5188\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5450 - val_loss: 0.5138\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.5598 - val_loss: 0.5082\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.5520 - val_loss: 0.5034\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.5384 - val_loss: 0.4988\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.5380 - val_loss: 0.4945\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.5120 - val_loss: 0.4910\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.5370 - val_loss: 0.4872\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.5249 - val_loss: 0.4837\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4979 - val_loss: 0.4806\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.5104 - val_loss: 0.4778\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.5084 - val_loss: 0.4746\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.5041 - val_loss: 0.4717\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4798 - val_loss: 0.4688\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.5037 - val_loss: 0.4660\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.5055 - val_loss: 0.4637\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.5388 - val_loss: 0.4615\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.5251 - val_loss: 0.4588\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4835 - val_loss: 0.4565\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.4824 - val_loss: 0.4545\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4788 - val_loss: 0.4526\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4737 - val_loss: 0.4507\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.4743 - val_loss: 0.4489\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4945 - val_loss: 0.4473\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4467 - val_loss: 0.4456\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4784 - val_loss: 0.4439\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4850 - val_loss: 0.4422\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4760 - val_loss: 0.4408\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4746 - val_loss: 0.4392\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4804 - val_loss: 0.4376\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4558 - val_loss: 0.4364\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4569 - val_loss: 0.4352\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4729 - val_loss: 0.4342\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4692 - val_loss: 0.4329\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4747 - val_loss: 0.4317\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4573 - val_loss: 0.4305\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4614 - val_loss: 0.4293\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4755 - val_loss: 0.4284\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4692 - val_loss: 0.4272\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.4694 - val_loss: 0.4261\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4508 - val_loss: 0.4249\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4557 - val_loss: 0.4241\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4609 - val_loss: 0.4231\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4439 - val_loss: 0.4222\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 809us/step - loss: 0.4547 - val_loss: 0.4215\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4437 - val_loss: 0.4208\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4201\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4595 - val_loss: 0.4189\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4540 - val_loss: 0.4182\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4220 - val_loss: 0.4174\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4205 - val_loss: 0.4166\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4464 - val_loss: 0.4159\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4357 - val_loss: 0.4153\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4272 - val_loss: 0.4146\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4425 - val_loss: 0.4135\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4283 - val_loss: 0.4127\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4336 - val_loss: 0.4120\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4289 - val_loss: 0.4118\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4525 - val_loss: 0.4108\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4294 - val_loss: 0.4102\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4297 - val_loss: 0.4095\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4423 - val_loss: 0.4090\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4424 - val_loss: 0.4083\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4624 - val_loss: 0.4075\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4303 - val_loss: 0.4071\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4319 - val_loss: 0.4066\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4321 - val_loss: 0.4059\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4358 - val_loss: 0.4054\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.4217 - val_loss: 0.4047\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.4391 - val_loss: 0.4045\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4526 - val_loss: 0.4040\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4358 - val_loss: 0.4032\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4439 - val_loss: 0.4025\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4161 - val_loss: 0.4019\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4157 - val_loss: 0.4015\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4319 - val_loss: 0.4009\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4115 - val_loss: 0.4005\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4423 - val_loss: 0.3999\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4463 - val_loss: 0.3994\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.4564 - val_loss: 0.3989\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4412 - val_loss: 0.3985\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4257 - val_loss: 0.3978\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4427 - val_loss: 0.3975\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4164 - val_loss: 0.3970\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4250 - val_loss: 0.3965\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4215 - val_loss: 0.3961\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4008 - val_loss: 0.3957\n",
      "121/121 [==============================] - 0s 387us/step - loss: 0.3948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-1.29271046e+14 -4.13373619e-01 -3.64309301e-01             nan\n",
      " -2.99838275e-01 -3.22979639e-01 -3.24429383e-01 -3.60941599e-01\n",
      " -3.02069416e-01 -4.23749934e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002BE5C709DF0>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b92160274eb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    877\u001b[0m                 **self.best_params_))\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     86\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002BE5C709DF0>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "#randomized-search-cv page 321 in hands on machine learning\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\":[0,1,2,3],\n",
    "    \"n_nuerons\":np.arange(100),\n",
    "    \"learning_rate\":reciprocal(3e-4,3e-2)\n",
    "}\n",
    "\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg,param_distribs,n_iter=10,cv=3)\n",
    "rnd_search_cv.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58dcdff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02388513238833371, 'n_hidden': 2, 'n_nuerons': 63}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72282144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.29983827471733093"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7a11b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1308 - val_loss: 1.0021\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.5195 - val_loss: 1.4611\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4547 - val_loss: 0.3574\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 786us/step - loss: 0.3769 - val_loss: 0.3255\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.3529 - val_loss: 0.3393\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3510 - val_loss: 0.3247\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3460 - val_loss: 0.3119\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.3300 - val_loss: 0.3102\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3128 - val_loss: 0.3034\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.3069 - val_loss: 0.3463\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 684us/step - loss: 0.3094 - val_loss: 0.3049\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3157 - val_loss: 0.2946\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.2888 - val_loss: 0.2955\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.2934 - val_loss: 0.2860\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.2950 - val_loss: 0.2783\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.2984 - val_loss: 0.3004\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 786us/step - loss: 0.3032 - val_loss: 0.2778\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.2831 - val_loss: 0.2910\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.2852 - val_loss: 0.2889\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.2928 - val_loss: 0.2849\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.2848 - val_loss: 0.2755\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.2810 - val_loss: 0.2751\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.2883 - val_loss: 0.2961\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.2764 - val_loss: 0.2834\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.2820 - val_loss: 0.2821\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.2809 - val_loss: 0.2916\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.2802 - val_loss: 0.2757\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.2682 - val_loss: 0.2858\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 715us/step - loss: 0.2751 - val_loss: 0.2866\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.2808 - val_loss: 0.2757\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.2665 - val_loss: 0.2693\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.2761 - val_loss: 0.2619\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.2692 - val_loss: 0.2781\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.2604 - val_loss: 0.2664\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.2674 - val_loss: 0.2730\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.2701 - val_loss: 0.2617\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.2649 - val_loss: 0.2778\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 734us/step - loss: 0.2653 - val_loss: 0.2620\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.2689 - val_loss: 0.2778\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.2591 - val_loss: 0.2627\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.2606 - val_loss: 0.2645\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.2715 - val_loss: 0.2816\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 723us/step - loss: 0.2724 - val_loss: 0.2612\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.2710 - val_loss: 0.2722\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2614 - val_loss: 0.2656\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.2590 - val_loss: 0.2649\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 728us/step - loss: 0.2470 - val_loss: 0.2798\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.2670 - val_loss: 0.2796\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.2648 - val_loss: 0.2554\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.2602 - val_loss: 0.2602\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.2588 - val_loss: 0.2611\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.2576 - val_loss: 0.2578\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.2649 - val_loss: 0.2867\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.2520 - val_loss: 0.2786\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.2455 - val_loss: 0.2720\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.2530 - val_loss: 0.2635\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.2419 - val_loss: 0.2681\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 803us/step - loss: 0.2619 - val_loss: 0.2636\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.2543 - val_loss: 0.2673\n",
      "162/162 [==============================] - 0s 475us/step - loss: 0.2794\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_hidden=2,n_nuerons=63,learning_rate=0.02388513238833371,inputshape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=inputshape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_nuerons,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimezer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\",optimizer=optimezer)\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid),callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
